{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":114239,"databundleVersionId":14210809,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:15:40.629754Z","iopub.execute_input":"2025-12-03T20:15:40.629980Z","iopub.status.idle":"2025-12-03T20:15:42.315493Z","shell.execute_reply.started":"2025-12-03T20:15:40.629953Z","shell.execute_reply":"2025-12-03T20:15:42.314845Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_inference_server.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_gateway.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/__init__.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/templates.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/relay.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/__init__.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/__init__.py\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w17.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w05.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w10.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w03.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w18.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w05.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w11.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w12.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w16.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w06.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w18.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w10.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w02.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w08.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w12.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w13.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w15.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w03.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w13.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w15.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w16.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w01.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w04.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w14.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w14.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w09.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w01.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w07.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w11.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w06.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w04.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w09.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w17.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w07.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w08.csv\n/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w02.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Verificar versi√≥n de Python y TensorFlow\nimport sys\nimport tensorflow as tf\n\nprint(\"Python:\", sys.version)\nprint(\"TensorFlow:\", tf.__version__)\n\n# Verificar GPU disponible\nprint(\"GPU disponible:\", tf.config.list_physical_devices('GPU'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:15:42.317145Z","iopub.execute_input":"2025-12-03T20:15:42.317601Z","iopub.status.idle":"2025-12-03T20:15:59.681993Z","shell.execute_reply.started":"2025-12-03T20:15:42.317572Z","shell.execute_reply":"2025-12-03T20:15:59.681182Z"}},"outputs":[{"name":"stderr","text":"2025-12-03 20:15:43.892630: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764792944.109763      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764792944.175395      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nTensorFlow: 2.18.0\nGPU disponible: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Carga de datos","metadata":{}},{"cell_type":"code","source":"import os\nimport cudf\n\n# Define la ruta base donde se encuentran los archivos de datos de la NFL\nTRAIN_DIR = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/train\"\n\n# ------------------------------\n# 1. Seleccionar semanas v√°lidas (w01 a w18)\n# ------------------------------\n# Se generan los nombres de los archivos para las 18 semanas, asegurando\n# que el n√∫mero tenga dos d√≠gitos (ej: 'w01', 'w18').\nvalid_weeks = [f\"w{str(i).zfill(2)}\" for i in range(1, 19)]\nprint(\"Semanas a cargar:\", valid_weeks)\n\n# ------------------------------\n# 2. Cargar INPUTS (Secuencias Hist√≥ricas)\n# ------------------------------\ndfs_in = []\n\nfor w in valid_weeks:\n    file_path = f\"{TRAIN_DIR}/input_2023_{w}.csv\"\n    print(\"Cargando INPUT:\", file_path)\n    # cudf.read_csv carga el CSV directamente en la memoria de la GPU\n    df = cudf.read_csv(file_path)\n    dfs_in.append(df)\n\n# Concatena todos los DataFrames de input de las semanas en un √∫nico DataFrame de cuDF\ntrain_input = cudf.concat(dfs_in, ignore_index=True)\n\n# ------------------------------\n# 3. Cargar OUTPUTS (Targets de Predicci√≥n)\n# ------------------------------\ndfs_out = []\n\nfor w in valid_weeks:\n    file_path = f\"{TRAIN_DIR}/output_2023_{w}.csv\"\n    print(\"Cargando OUTPUT:\", file_path)\n    # Carga los targets de predicci√≥n (la posici√≥n futura x, y)\n    df = cudf.read_csv(file_path)\n    dfs_out.append(df)\n\n# Concatena todos los DataFrames de output de las semanas\ntrain_output = cudf.concat(dfs_out, ignore_index=True)\n\n# ------------------------------\n# 4. Mostrar resultados\n# ------------------------------\nprint(\"\\nTama√±os cargados:\")\nprint(\"train_input:\", train_input.shape)\nprint(\"train_output:\", train_output.shape)\n\n# Muestra la cabecera para verificar la estructura\ntrain_input.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:15:59.682888Z","iopub.execute_input":"2025-12-03T20:15:59.683522Z","iopub.status.idle":"2025-12-03T20:16:08.358421Z","shell.execute_reply.started":"2025-12-03T20:15:59.683503Z","shell.execute_reply":"2025-12-03T20:16:08.357355Z"}},"outputs":[{"name":"stdout","text":"Semanas a cargar: ['w01', 'w02', 'w03', 'w04', 'w05', 'w06', 'w07', 'w08', 'w09', 'w10', 'w11', 'w12', 'w13', 'w14', 'w15', 'w16', 'w17', 'w18']\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w01.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w02.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w03.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w04.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w05.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w06.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w07.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w08.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w09.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w10.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w11.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w12.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w13.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w14.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w15.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w16.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w17.csv\nCargando INPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w18.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w01.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w02.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w03.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w04.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w05.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w06.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w07.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w08.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w09.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w10.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w11.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w12.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w13.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w14.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w15.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w16.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w17.csv\nCargando OUTPUT: /kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w18.csv\n\nTama√±os cargados:\ntrain_input: (4880579, 23)\ntrain_output: (562936, 6)\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      game_id  play_id  player_to_predict  nfl_id  frame_id play_direction  \\\n0  2023090700      101              False   54527         1          right   \n1  2023090700      101              False   54527         2          right   \n2  2023090700      101              False   54527         3          right   \n3  2023090700      101              False   54527         4          right   \n4  2023090700      101              False   54527         5          right   \n\n   absolute_yardline_number player_name player_height  player_weight  ...  \\\n0                        42  Bryan Cook           6-1            210  ...   \n1                        42  Bryan Cook           6-1            210  ...   \n2                        42  Bryan Cook           6-1            210  ...   \n3                        42  Bryan Cook           6-1            210  ...   \n4                        42  Bryan Cook           6-1            210  ...   \n\n          player_role      x      y     s     a     dir       o  \\\n0  Defensive Coverage  52.33  36.94  0.09  0.39  322.40  238.24   \n1  Defensive Coverage  52.33  36.94  0.04  0.61  200.89  236.05   \n2  Defensive Coverage  52.33  36.93  0.12  0.73  147.55  240.60   \n3  Defensive Coverage  52.35  36.92  0.23  0.81  131.40  244.25   \n4  Defensive Coverage  52.37  36.90  0.35  0.82  123.26  244.25   \n\n   num_frames_output  ball_land_x  ball_land_y  \n0                 21    63.259998        -0.22  \n1                 21    63.259998        -0.22  \n2                 21    63.259998        -0.22  \n3                 21    63.259998        -0.22  \n4                 21    63.259998        -0.22  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_id</th>\n      <th>play_id</th>\n      <th>player_to_predict</th>\n      <th>nfl_id</th>\n      <th>frame_id</th>\n      <th>play_direction</th>\n      <th>absolute_yardline_number</th>\n      <th>player_name</th>\n      <th>player_height</th>\n      <th>player_weight</th>\n      <th>...</th>\n      <th>player_role</th>\n      <th>x</th>\n      <th>y</th>\n      <th>s</th>\n      <th>a</th>\n      <th>dir</th>\n      <th>o</th>\n      <th>num_frames_output</th>\n      <th>ball_land_x</th>\n      <th>ball_land_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>1</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.33</td>\n      <td>36.94</td>\n      <td>0.09</td>\n      <td>0.39</td>\n      <td>322.40</td>\n      <td>238.24</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>2</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.33</td>\n      <td>36.94</td>\n      <td>0.04</td>\n      <td>0.61</td>\n      <td>200.89</td>\n      <td>236.05</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>3</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.33</td>\n      <td>36.93</td>\n      <td>0.12</td>\n      <td>0.73</td>\n      <td>147.55</td>\n      <td>240.60</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>4</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.35</td>\n      <td>36.92</td>\n      <td>0.23</td>\n      <td>0.81</td>\n      <td>131.40</td>\n      <td>244.25</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>5</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.37</td>\n      <td>36.90</td>\n      <td>0.35</td>\n      <td>0.82</td>\n      <td>123.26</td>\n      <td>244.25</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"\n\nEste bloque de c√≥digo se encarga de cargar todos los archivos de entrada (input) y salida (output) correspondientes a las semanas w01 a w18 de la competici√≥n NFL Big Data Bowl 2026, utilizando cuDF para mantener todo el procesamiento directamente en la GPU.\n\n### üß© 1. Definici√≥n de semanas v√°lidas\n\nSe genera una lista de semanas del 1 al 18 en formato w01, w02, ‚Ä¶, w18. Esto permite automatizar la carga de todos los archivos disponibles sin escribir rutas manualmente.\n\n### üß© 2. Carga de INPUTS (Secuencias hist√≥ricas)\n\nPara cada semana:\n\n- Se construye din√°micamente la ruta al archivo input_2023_wXX.csv.\n\n- Se carga utilizando cudf.read_csv, asegurando lectura directa en GPU.\n\n- Todos los DataFrames se concatenan en un √∫nico train_input.\n\n- Estos archivos contienen las trayectorias pasadas de los jugadores, usadas como entrada del modelo.\n\n### üß© 3. Carga de OUTPUTS (Targets / Labels)\n\nDe manera equivalente:\n\n- Se cargan los archivos output_2023_wXX.csv.\n\n- Se concatenan en train_output.\n\n- Estos archivos contienen los valores objetivo (posici√≥n futura x, y) que el modelo debe aprender a predecir.\n\n### üß© 4. Inspecci√≥n final\n\nAl final se muestra:\n\n- El tama√±o total de los datasets cargados.\n\n- Una vista previa del DataFrame de entrada.\n\n### ‚úÖ Resultado\n\nAl terminar este proceso tendr√°s cargados en GPU:\n\n- train_input: todas las secuencias hist√≥ricas de las semanas 1‚Äì18\n\n- train_output: todos los targets correspondientes\n\n- Listos para iniciar procesamiento, ingenier√≠a de features o entrenamiento del modelo.","metadata":{}},{"cell_type":"markdown","source":"# An√°lisis del conjunto de datos\n---\n## 1. Descripci√≥n general del dataset y del objetivo del concurso\nLa competencia **[NFL Big Data Bowl 2026# ](https://www.kaggle.com/competitions/nfl-big-data-bowl-2026-prediction)** es un reto anual organizado en colaboraci√≥n con la **National Football League (NFL)** y tiene como prop√≥sito impulsar la innovaci√≥n en el an√°lisis de datos deportivos, especialmente en **jugadas de f√∫tbol americano profesional**.\n\nEl objetivo es utilizar datos de **seguimiento de jugadores en el campo (player tracking)** junto con informaci√≥n contextual de jugadas, equipos y jugadores, para **predecir eventos o m√©tricas espec√≠ficas de rendimiento en tiempo real**. Este tipo de an√°lisis permite desarrollar modelos predictivos avanzados aplicables a estrategias de juego, scouting y an√°lisis estad√≠stico de alto nivel.\n\n---\n\n### Objetivo principal del concurso\n\nEl **objetivo central** es desarrollar modelos predictivos que **estimen resultados de jugadas ofensivas a partir de datos de posici√≥n y contexto**.  \nEn esta edici√≥n, los participantes deben:\n\n- Utilizar informaci√≥n de **seguimiento de jugadores (tracking)** en jugadas seleccionadas.\n- Construir un modelo que **prediga una variable de salida continua**, relacionada con el desempe√±o ofensivo (por ejemplo, yardas ganadas, probabilidad de conversi√≥n o m√©tricas derivadas).\n- Entrenar, validar y evaluar modelos de regresi√≥n capaces de generalizar a jugadas no vistas.\n\nEl **score oficial** de la competencia se basa en una m√©trica de error (por ejemplo, MSE o MAE) que mide la **precisi√≥n de la predicci√≥n** frente al resultado real de la jugada.\n\n---\n## 2. Descripci√≥n de variables de entrada y salida\n\n| **Variable** | **Tipo de Dato** | **Descripci√≥n** | **Rol en el Modelo** |\n|---------------|------------------|------------------|-----------------------|\n| `game_id` | Num√©rica | Identificador √∫nico del juego. | Identificaci√≥n / Uni√≥n |\n| `play_id` | Num√©rica | Identificador de la jugada (no √∫nico entre juegos). | Identificaci√≥n / Uni√≥n |\n| `player_to_predict` | Booleana | Indica si se deben predecir las coordenadas (x, y) de este jugador. | Indicador de objetivo |\n| `nfl_id` | Num√©rica | Identificador √∫nico del jugador en la NFL. | Identificaci√≥n |\n| `frame_id` | Num√©rica | N√∫mero de frame dentro de la jugada. Inicia en 1. | Variable temporal |\n| `play_direction` | Categ√≥rica | Direcci√≥n del ataque: izquierda o derecha. | Contextual / Categ√≥rica |\n| `absolute_yardline_number` | Num√©rica | Distancia desde la zona de anotaci√≥n del equipo en posesi√≥n (yardas). | Posicional |\n| `player_name` | Texto | Nombre del jugador. | Informativa (no predictiva directa) |\n| `player_height` | Texto / Num√©rica | Altura del jugador en pies y pulgadas (ft-in). | Fisiol√≥gica |\n| `player_weight` | Num√©rica | Peso del jugador en libras (lbs). | Fisiol√≥gica |\n| `player_birth_date` | Fecha | Fecha de nacimiento del jugador (yyyy-mm-dd). | Demogr√°fica |\n| `player_position` | Categ√≥rica | Posici√≥n t√≠pica en el campo (QB, WR, CB, etc.). | Categ√≥rica |\n| `player_side` | Categ√≥rica | Lado del equipo: Ofensivo o Defensivo. | Categ√≥rica |\n| `player_role` | Categ√≥rica | Rol del jugador en la jugada (Passer, Receiver, Defensive Coverage, etc.). | Categ√≥rica / Contextual |\n| `x` | Num√©rica | Posici√≥n del jugador sobre el eje longitudinal del campo (0 ‚Äì 120 yardas). | Posici√≥n espacial |\n| `y` | Num√©rica | Posici√≥n del jugador sobre el eje transversal del campo (0 ‚Äì 53.3 yardas). | Posici√≥n espacial |\n| `s` | Num√©rica | Velocidad del jugador (yardas/segundo). | Cin√©tica |\n| `a` | Num√©rica | Aceleraci√≥n del jugador (yardas/segundo¬≤). | Cin√©tica |\n| `o` | Num√©rica | Orientaci√≥n del jugador en grados (hacia d√≥nde est√° mirando). | Angular |\n| `dir` | Num√©rica | Direcci√≥n de movimiento en grados (hacia d√≥nde se desplaza). | Angular |\n| `num_frames_output` | Num√©rica | N√∫mero de frames futuros a predecir para esa jugada/jugador. | Temporal / Objetivo de predicci√≥n |\n| `ball_land_x` | Num√©rica | Coordenada X donde se espera que aterrice el bal√≥n. | Contextual / Futura |\n| `ball_land_y` | Num√©rica | Coordenada Y donde se espera que aterrice el bal√≥n. | Contextual / Futura |\n| `x` *(en output)* | Num√©rica | Posici√≥n **real futura** del jugador en el eje longitudinal. | **Variable de salida (target)** |\n| `y` *(en output)* | Num√©rica | Posici√≥n **real futura** del jugador en el eje transversal. | **Variable de salida (target)** |\n\n---\n\n## 3. An√°lisis Exploratorio de Datos (EDA)\nEl an√°lisis exploratorio se realiza para comprender la estructura y comportamiento de las variables antes de construir modelos predictivos.  \nA continuaci√≥n, se describen los principales pasos aplicados sobre el conjunto de datos de seguimiento de jugadores (tracking data) de la NFL:","metadata":{}},{"cell_type":"markdown","source":"### Inspecci√≥n general de la base de datos","metadata":{}},{"cell_type":"code","source":"train_input.info #Muestra informaci√≥n general del DataFrame","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:16:08.359203Z","iopub.execute_input":"2025-12-03T20:16:08.360071Z","iopub.status.idle":"2025-12-03T20:16:08.407217Z","shell.execute_reply.started":"2025-12-03T20:16:08.360050Z","shell.execute_reply":"2025-12-03T20:16:08.406567Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<bound method DataFrame.info of             game_id  play_id  player_to_predict  nfl_id  frame_id  \\\n0        2023090700      101              False   54527         1   \n1        2023090700      101              False   54527         2   \n2        2023090700      101              False   54527         3   \n3        2023090700      101              False   54527         4   \n4        2023090700      101              False   54527         5   \n...             ...      ...                ...     ...       ...   \n4880574  2024010713     4018               True   52457        23   \n4880575  2024010713     4018               True   52457        24   \n4880576  2024010713     4018               True   52457        25   \n4880577  2024010713     4018               True   52457        26   \n4880578  2024010713     4018               True   52457        27   \n\n        play_direction  absolute_yardline_number     player_name  \\\n0                right                        42      Bryan Cook   \n1                right                        42      Bryan Cook   \n2                right                        42      Bryan Cook   \n3                right                        42      Bryan Cook   \n4                right                        42      Bryan Cook   \n...                ...                       ...             ...   \n4880574           left                        50  Chase Claypool   \n4880575           left                        50  Chase Claypool   \n4880576           left                        50  Chase Claypool   \n4880577           left                        50  Chase Claypool   \n4880578           left                        50  Chase Claypool   \n\n        player_height  player_weight  ...         player_role      x      y  \\\n0                 6-1            210  ...  Defensive Coverage  52.33  36.94   \n1                 6-1            210  ...  Defensive Coverage  52.33  36.94   \n2                 6-1            210  ...  Defensive Coverage  52.33  36.93   \n3                 6-1            210  ...  Defensive Coverage  52.35  36.92   \n4                 6-1            210  ...  Defensive Coverage  52.37  36.90   \n...               ...            ...  ...                 ...    ...    ...   \n4880574           6-4            227  ...   Targeted Receiver  41.61  17.57   \n4880575           6-4            227  ...   Targeted Receiver  40.82  17.52   \n4880576           6-4            227  ...   Targeted Receiver  40.03  17.46   \n4880577           6-4            227  ...   Targeted Receiver  39.24  17.36   \n4880578           6-4            227  ...   Targeted Receiver  38.45  17.24   \n\n            s     a     dir       o  num_frames_output  ball_land_x  \\\n0        0.09  0.39  322.40  238.24                 21    63.259998   \n1        0.04  0.61  200.89  236.05                 21    63.259998   \n2        0.12  0.73  147.55  240.60                 21    63.259998   \n3        0.23  0.81  131.40  244.25                 21    63.259998   \n4        0.35  0.82  123.26  244.25                 21    63.259998   \n...       ...   ...     ...     ...                ...          ...   \n4880574  7.81  0.58  267.16  296.92                 18    32.139999   \n4880575  7.92  0.19  266.40  292.80                 18    32.139999   \n4880576  7.92  0.69  265.49  290.54                 18    32.139999   \n4880577  7.94  1.46  263.26  287.74                 18    32.139999   \n4880578  7.89  2.06  261.04  285.48                 18    32.139999   \n\n         ball_land_y  \n0              -0.22  \n1              -0.22  \n2              -0.22  \n3              -0.22  \n4              -0.22  \n...              ...  \n4880574         6.71  \n4880575         6.71  \n4880576         6.71  \n4880577         6.71  \n4880578         6.71  \n\n[4880579 rows x 23 columns]>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"train_input.describe() #Muestra estad√≠sticas descriptivas b√°sicas de las columnas num√©ricas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:16:08.407812Z","iopub.execute_input":"2025-12-03T20:16:08.408059Z","iopub.status.idle":"2025-12-03T20:16:10.050697Z","shell.execute_reply.started":"2025-12-03T20:16:08.408040Z","shell.execute_reply":"2025-12-03T20:16:10.050067Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"            game_id       play_id        nfl_id      frame_id  \\\ncount  4.880579e+06  4.880579e+06  4.880579e+06  4.880579e+06   \nmean   2.023155e+09  2.196409e+03  4.955890e+04  1.613179e+01   \nstd    2.011405e+05  1.246426e+03  5.210338e+03  1.113008e+01   \nmin    2.023091e+09  5.400000e+01  3.084200e+04  1.000000e+00   \n25%    2.023101e+09  1.150000e+03  4.519800e+04  8.000000e+00   \n50%    2.023111e+09  2.171000e+03  5.241300e+04  1.500000e+01   \n75%    2.023121e+09  3.246000e+03  5.450000e+04  2.200000e+01   \nmax    2.024011e+09  5.258000e+03  5.667300e+04  1.230000e+02   \n\n       absolute_yardline_number  player_weight             x             y  \\\ncount              4.880579e+06   4.880579e+06  4.880579e+06  4.880579e+06   \nmean               6.055045e+01   2.112783e+02  6.050074e+01  2.681189e+01   \nstd                2.305935e+01   2.217747e+01  2.348919e+01  1.000620e+01   \nmin                1.100000e+01   1.530000e+02  4.100000e-01  6.200000e-01   \n25%                4.100000e+01   1.950000e+02  4.263000e+01  1.899000e+01   \n50%                6.100000e+01   2.070000e+02  6.041000e+01  2.685000e+01   \n75%                8.000000e+01   2.250000e+02  7.823000e+01  3.462000e+01   \nmax                1.090000e+02   3.580000e+02  1.198600e+02  5.288000e+01   \n\n                  s             a           dir             o  \\\ncount  4.880579e+06  4.880579e+06  4.880579e+06  4.880579e+06   \nmean   3.019878e+00  2.118335e+00  1.804972e+02  1.815366e+02   \nstd    2.227939e+00  1.415794e+00  1.007162e+02  9.800912e+01   \nmin    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n25%    1.090000e+00  1.010000e+00  9.091000e+01  9.174000e+01   \n50%    2.720000e+00  1.920000e+00  1.795600e+02  1.801400e+02   \n75%    4.620000e+00  3.040000e+00  2.708300e+02  2.715800e+02   \nmax    1.253000e+01  1.712000e+01  3.600000e+02  3.600000e+02   \n\n       num_frames_output   ball_land_x   ball_land_y  \ncount       4.880579e+06  4.880579e+06  4.880579e+06  \nmean        1.164147e+01  6.051581e+01  2.663766e+01  \nstd         5.331537e+00  2.529643e+01  1.543814e+01  \nmin         5.000000e+00 -5.260000e+00 -3.910000e+00  \n25%         8.000000e+00  4.261000e+01  1.330000e+01  \n50%         1.000000e+01  6.051000e+01  2.647000e+01  \n75%         1.400000e+01  7.847000e+01  3.987000e+01  \nmax         9.400000e+01  1.258500e+02  5.733000e+01  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_id</th>\n      <th>play_id</th>\n      <th>nfl_id</th>\n      <th>frame_id</th>\n      <th>absolute_yardline_number</th>\n      <th>player_weight</th>\n      <th>x</th>\n      <th>y</th>\n      <th>s</th>\n      <th>a</th>\n      <th>dir</th>\n      <th>o</th>\n      <th>num_frames_output</th>\n      <th>ball_land_x</th>\n      <th>ball_land_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n      <td>4.880579e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.023155e+09</td>\n      <td>2.196409e+03</td>\n      <td>4.955890e+04</td>\n      <td>1.613179e+01</td>\n      <td>6.055045e+01</td>\n      <td>2.112783e+02</td>\n      <td>6.050074e+01</td>\n      <td>2.681189e+01</td>\n      <td>3.019878e+00</td>\n      <td>2.118335e+00</td>\n      <td>1.804972e+02</td>\n      <td>1.815366e+02</td>\n      <td>1.164147e+01</td>\n      <td>6.051581e+01</td>\n      <td>2.663766e+01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.011405e+05</td>\n      <td>1.246426e+03</td>\n      <td>5.210338e+03</td>\n      <td>1.113008e+01</td>\n      <td>2.305935e+01</td>\n      <td>2.217747e+01</td>\n      <td>2.348919e+01</td>\n      <td>1.000620e+01</td>\n      <td>2.227939e+00</td>\n      <td>1.415794e+00</td>\n      <td>1.007162e+02</td>\n      <td>9.800912e+01</td>\n      <td>5.331537e+00</td>\n      <td>2.529643e+01</td>\n      <td>1.543814e+01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>2.023091e+09</td>\n      <td>5.400000e+01</td>\n      <td>3.084200e+04</td>\n      <td>1.000000e+00</td>\n      <td>1.100000e+01</td>\n      <td>1.530000e+02</td>\n      <td>4.100000e-01</td>\n      <td>6.200000e-01</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>5.000000e+00</td>\n      <td>-5.260000e+00</td>\n      <td>-3.910000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.023101e+09</td>\n      <td>1.150000e+03</td>\n      <td>4.519800e+04</td>\n      <td>8.000000e+00</td>\n      <td>4.100000e+01</td>\n      <td>1.950000e+02</td>\n      <td>4.263000e+01</td>\n      <td>1.899000e+01</td>\n      <td>1.090000e+00</td>\n      <td>1.010000e+00</td>\n      <td>9.091000e+01</td>\n      <td>9.174000e+01</td>\n      <td>8.000000e+00</td>\n      <td>4.261000e+01</td>\n      <td>1.330000e+01</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.023111e+09</td>\n      <td>2.171000e+03</td>\n      <td>5.241300e+04</td>\n      <td>1.500000e+01</td>\n      <td>6.100000e+01</td>\n      <td>2.070000e+02</td>\n      <td>6.041000e+01</td>\n      <td>2.685000e+01</td>\n      <td>2.720000e+00</td>\n      <td>1.920000e+00</td>\n      <td>1.795600e+02</td>\n      <td>1.801400e+02</td>\n      <td>1.000000e+01</td>\n      <td>6.051000e+01</td>\n      <td>2.647000e+01</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.023121e+09</td>\n      <td>3.246000e+03</td>\n      <td>5.450000e+04</td>\n      <td>2.200000e+01</td>\n      <td>8.000000e+01</td>\n      <td>2.250000e+02</td>\n      <td>7.823000e+01</td>\n      <td>3.462000e+01</td>\n      <td>4.620000e+00</td>\n      <td>3.040000e+00</td>\n      <td>2.708300e+02</td>\n      <td>2.715800e+02</td>\n      <td>1.400000e+01</td>\n      <td>7.847000e+01</td>\n      <td>3.987000e+01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.024011e+09</td>\n      <td>5.258000e+03</td>\n      <td>5.667300e+04</td>\n      <td>1.230000e+02</td>\n      <td>1.090000e+02</td>\n      <td>3.580000e+02</td>\n      <td>1.198600e+02</td>\n      <td>5.288000e+01</td>\n      <td>1.253000e+01</td>\n      <td>1.712000e+01</td>\n      <td>3.600000e+02</td>\n      <td>3.600000e+02</td>\n      <td>9.400000e+01</td>\n      <td>1.258500e+02</td>\n      <td>5.733000e+01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_input.head() #Muestra las primeras filas del dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:16:10.051333Z","iopub.execute_input":"2025-12-03T20:16:10.051507Z","iopub.status.idle":"2025-12-03T20:16:10.113009Z","shell.execute_reply.started":"2025-12-03T20:16:10.051493Z","shell.execute_reply":"2025-12-03T20:16:10.112368Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      game_id  play_id  player_to_predict  nfl_id  frame_id play_direction  \\\n0  2023090700      101              False   54527         1          right   \n1  2023090700      101              False   54527         2          right   \n2  2023090700      101              False   54527         3          right   \n3  2023090700      101              False   54527         4          right   \n4  2023090700      101              False   54527         5          right   \n\n   absolute_yardline_number player_name player_height  player_weight  ...  \\\n0                        42  Bryan Cook           6-1            210  ...   \n1                        42  Bryan Cook           6-1            210  ...   \n2                        42  Bryan Cook           6-1            210  ...   \n3                        42  Bryan Cook           6-1            210  ...   \n4                        42  Bryan Cook           6-1            210  ...   \n\n          player_role      x      y     s     a     dir       o  \\\n0  Defensive Coverage  52.33  36.94  0.09  0.39  322.40  238.24   \n1  Defensive Coverage  52.33  36.94  0.04  0.61  200.89  236.05   \n2  Defensive Coverage  52.33  36.93  0.12  0.73  147.55  240.60   \n3  Defensive Coverage  52.35  36.92  0.23  0.81  131.40  244.25   \n4  Defensive Coverage  52.37  36.90  0.35  0.82  123.26  244.25   \n\n   num_frames_output  ball_land_x  ball_land_y  \n0                 21    63.259998        -0.22  \n1                 21    63.259998        -0.22  \n2                 21    63.259998        -0.22  \n3                 21    63.259998        -0.22  \n4                 21    63.259998        -0.22  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>game_id</th>\n      <th>play_id</th>\n      <th>player_to_predict</th>\n      <th>nfl_id</th>\n      <th>frame_id</th>\n      <th>play_direction</th>\n      <th>absolute_yardline_number</th>\n      <th>player_name</th>\n      <th>player_height</th>\n      <th>player_weight</th>\n      <th>...</th>\n      <th>player_role</th>\n      <th>x</th>\n      <th>y</th>\n      <th>s</th>\n      <th>a</th>\n      <th>dir</th>\n      <th>o</th>\n      <th>num_frames_output</th>\n      <th>ball_land_x</th>\n      <th>ball_land_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>1</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.33</td>\n      <td>36.94</td>\n      <td>0.09</td>\n      <td>0.39</td>\n      <td>322.40</td>\n      <td>238.24</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>2</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.33</td>\n      <td>36.94</td>\n      <td>0.04</td>\n      <td>0.61</td>\n      <td>200.89</td>\n      <td>236.05</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>3</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.33</td>\n      <td>36.93</td>\n      <td>0.12</td>\n      <td>0.73</td>\n      <td>147.55</td>\n      <td>240.60</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>4</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.35</td>\n      <td>36.92</td>\n      <td>0.23</td>\n      <td>0.81</td>\n      <td>131.40</td>\n      <td>244.25</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023090700</td>\n      <td>101</td>\n      <td>False</td>\n      <td>54527</td>\n      <td>5</td>\n      <td>right</td>\n      <td>42</td>\n      <td>Bryan Cook</td>\n      <td>6-1</td>\n      <td>210</td>\n      <td>...</td>\n      <td>Defensive Coverage</td>\n      <td>52.37</td>\n      <td>36.90</td>\n      <td>0.35</td>\n      <td>0.82</td>\n      <td>123.26</td>\n      <td>244.25</td>\n      <td>21</td>\n      <td>63.259998</td>\n      <td>-0.22</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows √ó 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Conteo de jugadores, jugadas y partidos √∫nicos","metadata":{}},{"cell_type":"code","source":"train_input[['game_id', 'play_id', 'nfl_id']].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:16:10.115147Z","iopub.execute_input":"2025-12-03T20:16:10.115357Z","iopub.status.idle":"2025-12-03T20:16:10.128813Z","shell.execute_reply.started":"2025-12-03T20:16:10.115341Z","shell.execute_reply":"2025-12-03T20:16:10.128046Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"game_id     272\nplay_id    4317\nnfl_id     1384\ndtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# Segunda parte (Analisis seccion por seccion del main)","metadata":{}},{"cell_type":"markdown","source":"## 4. Ingenier√≠a de caracter√≠sticas (Feature Engineering) y encoding","metadata":{}},{"cell_type":"code","source":"import cupy as cp\nimport numpy as np\nimport cudf\nfrom tqdm.auto import tqdm\n\n# ==========================================\n# 0. CONFIGURACI√ìN\n# ==========================================\nCONFIG = {\n    \"sequence_length\": 10,\n    \"max_frames_to_predict\": 10,\n    \"max_players\": 22\n}\n\n# ==========================================\n# 1. FUNCI√ìN DE AYUDA: Altura\n# ==========================================\ndef height_to_inches_gpu(df):\n    \"\"\"Convierte '6-2' a pulgadas (74.0).\"\"\"\n    if \"player_height\" not in df.columns:\n        return df\n        \n    split = df[\"player_height\"].astype(\"str\").str.split(\"-\", expand=True)\n    feet = split.iloc[:, 0].astype(\"float32\")\n    inches = split.iloc[:, 1].astype(\"float32\")\n    df[\"height_inches\"] = feet * 12 + inches\n    return df.drop(columns=[\"player_height\"])\n\n# ==========================================\n# 2. FUNCI√ìN DE INGENIER√çA DE FEATURES\n# ==========================================\ndef engineer_frame_features_gpu(input_df, output_df):\n    df = input_df.copy()\n    \n    # 1. Ordenar\n    df = df.sort_values([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])\n    \n    # 2. Altura\n    df = height_to_inches_gpu(df)\n    \n    # 3. Features B√°sicas\n    df[\"speed\"] = df[\"s\"].astype(\"float32\")\n    df[\"acceleration\"] = df[\"a\"].astype(\"float32\")\n    \n    # 4. Calcular dir_rad\n    if \"dir\" in df.columns:\n        df[\"dir_rad\"] = df[\"dir\"].astype(\"float32\") * (np.pi / 180.0)\n    else:\n        df[\"dir_rad\"] = 0.0\n        \n    # 5. Componentes de Velocidad\n    cp_dir_rad = df[\"dir_rad\"].to_cupy()\n    cp_speed = df[\"speed\"].to_cupy()\n    \n    df[\"vx\"] = cudf.Series(cp_speed * cp.cos(cp_dir_rad))\n    df[\"vy\"] = cudf.Series(cp_speed * cp.sin(cp_dir_rad))\n    \n    # 6. Encoding\n    cat_cols = [\"player_position\", \"player_role\"]\n    for col in cat_cols:\n        if col in df.columns:\n            df[col] = df[col].astype(\"category\")\n            df[f\"{col}_encoded\"] = df[col].cat.codes.astype(\"int16\")\n            \n    return {\"df_final\": df, \"output_df\": output_df}\n\n\n# ==========================================\n# 3. FUNCI√ìN BUILD DATASET (CORREGIDA .item())\n# ==========================================\ndef build_play_level_dataset(input_df, output_df, seq_len, H, max_players=22):\n    # Columnas\n    possible_cols = [\"x\",\"y\",\"speed\",\"acceleration\",\"vx\",\"vy\",\"dir_rad\"]\n    feat_cols = [c for c in possible_cols if c in input_df.columns]\n    num_feats = len(feat_cols)\n    \n    static_cols = [c for c in [\"height_inches\", \"player_weight\", \"player_position_encoded\"] if c in input_df.columns]\n    num_static_feats = len(static_cols)\n\n    unique_plays = input_df[[\"game_id\", \"play_id\"]].drop_duplicates().to_pandas()\n    \n    X_seq_list = []\n    X_static_list = []\n    Y_list = []\n    meta_list = []\n\n    for row in tqdm(unique_plays.itertuples(index=False), total=len(unique_plays), desc=\"Construyendo Dataset (GPU)\"):\n        gid, pid = row.game_id, row.play_id\n        \n        # Filtros\n        df_play = input_df[(input_df.game_id == gid) & (input_df.play_id == pid)].sort_values([\"nfl_id\", \"frame_id\"])\n        df_out = output_df[(output_df.game_id == gid) & (output_df.play_id == pid)].sort_values([\"nfl_id\", \"frame_id\"])\n        \n        players = df_play[\"nfl_id\"].unique().to_cupy()\n        \n        # Tensores\n        X_seq_play = cp.zeros((max_players, seq_len, num_feats), dtype=cp.float32)\n        X_static_play = cp.zeros((max_players, num_static_feats), dtype=cp.float32)\n        Y_play = cp.zeros((max_players, H, 2), dtype=cp.float32)\n        \n        # Iterar jugadores\n        for i, nfl_id_gpu in enumerate(players[:max_players]):\n            # --- FIX CR√çTICO: Convertir de CuPy a Python Scalar ---\n            nfl_id = nfl_id_gpu.item() \n            # ----------------------------------------------------\n            \n            p_data = df_play[df_play.nfl_id == nfl_id]\n            p_out = df_out[df_out.nfl_id == nfl_id]\n            \n            # Input Secuencial\n            seq_vals = p_data[feat_cols].tail(seq_len).to_cupy()\n            if len(seq_vals) > 0:\n                X_seq_play[i, -len(seq_vals):, :] = seq_vals\n                \n                # Input Est√°tico\n                if len(p_data) > 0:\n                    X_static_play[i, :] = p_data[static_cols].iloc[0].to_cupy()\n                \n                # Target Relativo\n                curr_x = seq_vals[-1, 0] \n                curr_y = seq_vals[-1, 1] \n                \n                future_vals = p_out[[\"x\", \"y\"]].head(H).to_cupy()\n                if len(future_vals) == H:\n                    Y_play[i, :, :] = future_vals - cp.array([curr_x, curr_y])\n                \n        X_seq_list.append(cp.asnumpy(X_seq_play))\n        X_static_list.append(cp.asnumpy(X_static_play))\n        Y_list.append(cp.asnumpy(Y_play))\n        meta_list.append({\"game_id\": gid, \"play_id\": pid}) # Simplifiqu√© a dict para coherencia\n\n    return {\n        \"X_seq\": np.array(X_seq_list), \n        \"X_static\": np.array(X_static_list), \n        \"Y\": np.array(Y_list),\n        \"meta\": meta_list\n    }\n\n# ==========================================\n# 4. EJECUCI√ìN\n# ==========================================\nprint(\"Generando features...\")\nfe = engineer_frame_features_gpu(train_input, train_output)\ndf_final = fe[\"df_final\"]\ntrain_output = fe[\"output_df\"]\n\n# Reducir memoria\ndef reduce_memory_footprint_gpu(df):\n    for col in df.columns:\n        if df[col].dtype == 'float64':\n            df[col] = df[col].astype('float32')\n    return df\n\ndf_final = reduce_memory_footprint_gpu(df_final)\ntrain_output = reduce_memory_footprint_gpu(train_output)\n\nprint(\"Construyendo tensores finales...\")\ndataset_play = build_play_level_dataset(\n    input_df=df_final,\n    output_df=train_output,\n    seq_len=CONFIG[\"sequence_length\"],\n    H=CONFIG[\"max_frames_to_predict\"],\n    max_players=CONFIG[\"max_players\"]\n)\n\nprint(\"‚úÖ Dataset construido con √©xito.\")\nprint(\"Formas:\")\nprint(\"X_seq:\", dataset_play[\"X_seq\"].shape)\nprint(\"Y (Relativo):\", dataset_play[\"Y\"].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:16:10.129836Z","iopub.execute_input":"2025-12-03T20:16:10.131543Z","iopub.status.idle":"2025-12-03T20:52:58.091146Z","shell.execute_reply.started":"2025-12-03T20:16:10.131513Z","shell.execute_reply":"2025-12-03T20:52:58.090511Z"}},"outputs":[{"name":"stdout","text":"Generando features...\nConstruyendo tensores finales...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Construyendo Dataset (GPU):   0%|          | 0/14108 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"887c2156d28d46129901049269382e87"}},"metadata":{}},{"name":"stdout","text":"‚úÖ Dataset construido con √©xito.\nFormas:\nX_seq: (14108, 22, 10, 7)\nY (Relativo): (14108, 22, 10, 2)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Importar numpy si se necesita m√°s adelante\nimport numpy as np\n\n# Diccionario central de configuraci√≥n del dataset y modelo\nCONFIG = {\n    # Frames hist√≥ricos usados como entrada\n    \"sequence_length\": 10,\n    \n    # Frames futuros que el modelo debe predecir\n    \"max_frames_to_predict\": 10,\n    \n    # M√°ximo n√∫mero de jugadores por jugada\n    \"max_players\": 22,\n    \n    # Par√°metros auxiliares\n    \"batch_size\": 32,\n    \"random_seed\": 42\n}\n\n# Verificaci√≥n r√°pida de los valores definidos\nprint(\"Configuraci√≥n definida exitosamente.\")\nprint(f\"Longitud de la secuencia (seq_len): {CONFIG['sequence_length']}\")\nprint(f\"Horizonte de predicci√≥n (H): {CONFIG['max_frames_to_predict']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:52:58.091998Z","iopub.execute_input":"2025-12-03T20:52:58.092610Z","iopub.status.idle":"2025-12-03T20:52:58.097084Z","shell.execute_reply.started":"2025-12-03T20:52:58.092590Z","shell.execute_reply":"2025-12-03T20:52:58.096479Z"}},"outputs":[{"name":"stdout","text":"Configuraci√≥n definida exitosamente.\nLongitud de la secuencia (seq_len): 10\nHorizonte de predicci√≥n (H): 10\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"En esta etapa los datos crudos cargados en GPU se transforman en un conjunto de caracter√≠sticas estructuradas, eficientes y directamente utilizables por el modelo. El objetivo es generar informaci√≥n descriptiva por frame, optimizar memoria y finalmente organizar todo en secuencias por jugada.\n\n###  4.1 Generaci√≥n de frame-level features\n\nPrimero se crean las caracter√≠sticas a nivel frame para cada jugador y cada instante de tiempo.\nEste proceso incluye c√°lculos como posiciones relativas, velocidades, aceleraciones, √°ngulos, distancias entre jugadores y m√©tricas espaciales relevantes para jugadas de la NFL.\nEl resultado es un DataFrame enriquecido con todas las features necesarias y un conjunto de targets alineados para la predicci√≥n de posiciones futuras.\n\n###  4.2 Optimizaci√≥n de memoria en GPU\n\nUna vez generadas las features, ambos DataFrames (inputs y targets) se someten a un proceso de reducci√≥n de memoria.\nEste paso ajusta los tipos de datos al tama√±o m√≠nimo posible sin p√©rdida de informaci√≥n √∫til, permitiendo trabajar con millones de filas en GPU sin llegar a los l√≠mites de VRAM.\n\n###  4.3 Construcci√≥n del play-level dataset\n\nFinalmente, se agrupan los datos por jugada y se construyen las secuencias hist√≥ricas y los horizontes futuros definidos en la configuraci√≥n.\nCada jugada produce:\n\n- Secuencias temporales con longitud configurada\n\n- Targets sobre los frames futuros\n\n- Informaci√≥n est√°tica del jugador o de la jugada\n\n- M√°scaras para manejar jugadores no presentes o padding\n\nEl resultado es un dataset completo, ordenado y listo para ser utilizado en modelos secuenciales como LSTM o Transformers dedicados a predecir trayectorias de jugadores.","metadata":{}},{"cell_type":"markdown","source":"## 5. Guardado y carga del dataset a nivel jugada (Play-Level Dataset)\n","metadata":{}},{"cell_type":"code","source":"# Guardado de datos procesados (Checkpoint)\n\nimport numpy as np\nimport pickle\nimport os\n\n# Nombre del archivo donde se guardar√°n los arrays del dataset\nfile_name = \"data_play_level.npz\"\n\n# -----------------------------------------------------------\n# CORRECCI√ìN: Ajuste de nombre de clave\n# -----------------------------------------------------------\n# En el bloque anterior la clave se defini√≥ como \"meta\", aqu√≠ aseguramos que la encuentre\nmeta_list = dataset_play.get(\"meta\", dataset_play.get(\"meta_list\")) \n\nif meta_list is None:\n    print(\"‚ö†Ô∏è ALERTA: No se encontr√≥ la lista de metadatos. Verifica el paso anterior.\")\nelse:\n    # Guardar la metadata con pickle\n    with open(\"meta_list.pkl\", \"wb\") as f:\n        pickle.dump(meta_list, f)\n    print(\"‚úÖ Metadatos guardados en: meta_list.pkl\")\n\n# Seleccionar solo los arrays NumPy que ser√°n almacenados en el .npz\narrays_to_save = {\n    \"X_seq\": dataset_play[\"X_seq\"],\n    \"X_static\": dataset_play[\"X_static\"],\n    \"Y\": dataset_play[\"Y\"]\n}\n\n# Guardado comprimido de los arrays en formato .npz\nnp.savez_compressed(file_name, **arrays_to_save)\n\nprint(f\"‚úÖ Arrays guardados en: {file_name}\")\nprint(\"   (Si se reinicia el kernel, puedes cargar esto directamente sin re-procesar)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:52:58.097720Z","iopub.execute_input":"2025-12-03T20:52:58.097969Z","iopub.status.idle":"2025-12-03T20:53:01.492909Z","shell.execute_reply.started":"2025-12-03T20:52:58.097927Z","shell.execute_reply":"2025-12-03T20:53:01.492296Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Metadatos guardados en: meta_list.pkl\n‚úÖ Arrays guardados en: data_play_level.npz\n   (Si se reinicia el kernel, puedes cargar esto directamente sin re-procesar)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import numpy as np\nimport pickle\nimport os\n\nfile_name = \"data_play_level.npz\"\n\n# Verificaci√≥n de seguridad\nif not os.path.exists(file_name):\n    print(\"‚ö†Ô∏è No se encontr√≥ el archivo guardado. Debes ejecutar el bloque de procesamiento primero.\")\nelse:\n    # Cargar arrays\n    loaded_data = np.load(file_name, allow_pickle=True)\n\n    # Cargar metadatos\n    with open(\"meta_list.pkl\", \"rb\") as f:\n        meta_list_loaded = pickle.load(f)\n\n    # Reconstruir usando el MISMO NOMBRE de variable que el bloque de generaci√≥n\n    dataset_play = {\n        \"X_seq\": loaded_data[\"X_seq\"],\n        \"X_static\": loaded_data[\"X_static\"],\n        \"Y\": loaded_data[\"Y\"],\n        \"meta_list\": meta_list_loaded\n    }\n\n    print(\"‚úÖ ¬°Datos cargados y restaurados en variable 'dataset_play'!\")\n    print(f\"   - X_seq shape: {dataset_play['X_seq'].shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:53:01.493694Z","iopub.execute_input":"2025-12-03T20:53:01.493925Z","iopub.status.idle":"2025-12-03T20:53:02.045610Z","shell.execute_reply.started":"2025-12-03T20:53:01.493899Z","shell.execute_reply":"2025-12-03T20:53:02.044929Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ¬°Datos cargados y restaurados en variable 'dataset_play'!\n   - X_seq shape: (14108, 22, 10, 7)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Una vez generado el dataset final con las secuencias hist√≥ricas, caracter√≠sticas est√°ticas y los targets de predicci√≥n, es necesario almacenarlo de forma eficiente para evitar regenerar todo el procesamiento cada vez que se entrena o prueba un modelo.\nPara esto se utilizan dos archivos:\n\n- data_play_level.npz ‚Üí contiene los tensores NumPy (X_seq, X_static, Y) en formato comprimido.\n\n- meta_list.pkl ‚Üí almacena la metadata asociada a cada jugada, como identificadores, alineaciones y referencias necesarias para reconstrucciones posteriores.\n\n### 5.1 Guardado del dataset\n\nEl proceso de guardado extrae √∫nicamente los arrays NumPy del diccionario dataset_play y los almacena en un archivo .npz comprimido, lo que reduce significativamente el espacio necesario.\nLa metadata, al ser una lista de diccionarios, se guarda por separado mediante pickle, ya que el formato .npz no soporta este tipo de estructuras.\n\nEste paso permite:\n\n- Evitar repetir la ingenier√≠a de caracter√≠sticas.\n\n- Mover datos f√°cilmente entre m√°quinas o sesiones.\n\n- Mantener una copia compacta del dataset final.\n\n### 5.2 Carga del dataset\n\n- Para reconstruir el dataset:\n\n- Se cargan los arrays desde el archivo .npz.\n\n- Se recupera la metadata desde el archivo .pkl.\n\n- Ambos se ensamblan nuevamente en un diccionario id√©ntico al original.\n\nDe esta forma, dataset_play_loaded queda listo para alimentar modelos sin necesidad de rehacer el pipeline de procesamiento.","metadata":{}},{"cell_type":"markdown","source":"## 6. Divisi√≥n entre Entrenamiento (80%) y Validaci√≥n (20%)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport gc\nfrom sklearn.model_selection import train_test_split\n\n# ------------------------------------------------------------\n# 1. Extracci√≥n de las variables\n# ------------------------------------------------------------\n# Extraemos referencias (no copias todav√≠a)\nX_seq = dataset_play[\"X_seq\"]       # (N, seq_len, players, feats)\nX_static = dataset_play[\"X_static\"] # (N, players, static_feats)\nY = dataset_play[\"Y\"]               # (N, players, H, 2)\n\nprint(f\"Total muestras antes del split: {X_seq.shape[0]}\")\n\n# ------------------------------------------------------------\n# 2. Realizar el Split 80/20 SIMULT√ÅNEO\n# ------------------------------------------------------------\nRANDOM_STATE = 42\nTEST_SIZE = 0.20\n\n# Al pasar los 3 arrays juntos, sklearn asegura que se mezclen y corten EXACTAMENTE igual\nX_seq_train, X_seq_val, X_static_train, X_static_val, Y_train, Y_val = train_test_split(\n    X_seq, X_static, Y, \n    test_size=TEST_SIZE, \n    random_state=RANDOM_STATE\n)\n\n# ------------------------------------------------------------\n# 3. Limpieza de Memoria (CR√çTICO EN KAGGLE)\n# ------------------------------------------------------------\n# Ya tenemos train y val, no necesitamos el dataset gigante original\ndel dataset_play\ndel X_seq, X_static, Y\ngc.collect()\n\n# ------------------------------------------------------------\n# 4. Verificaci√≥n\n# ------------------------------------------------------------\nN_train = X_seq_train.shape[0]\nN_val = X_seq_val.shape[0]\n\nprint(\"‚úÖ ¬°Split 80/20 completado y memoria liberada!\")\nprint(f\"Entrenamiento: {N_train} jugadas\")\nprint(f\"Validaci√≥n:    {N_val} jugadas\")\nprint(f\"X_seq_train:   {X_seq_train.shape}\")\nprint(f\"Y_train:       {Y_train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:53:02.046327Z","iopub.execute_input":"2025-12-03T20:53:02.046561Z","iopub.status.idle":"2025-12-03T20:53:02.452916Z","shell.execute_reply.started":"2025-12-03T20:53:02.046535Z","shell.execute_reply":"2025-12-03T20:53:02.452237Z"}},"outputs":[{"name":"stdout","text":"Total muestras antes del split: 14108\n‚úÖ ¬°Split 80/20 completado y memoria liberada!\nEntrenamiento: 11286 jugadas\nValidaci√≥n:    2822 jugadas\nX_seq_train:   (11286, 22, 10, 7)\nY_train:       (11286, 22, 10, 2)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Una vez construido el dataset a nivel de jugada, es necesario dividirlo en conjuntos de entrenamiento y validaci√≥n para poder entrenar modelos de manera correcta y evaluar su desempe√±o.\n\n###  6.1 Variables extra√≠das del dataset\n\nSe toman los tres componentes principales del dataset:\n\n- X_seq ‚Üí secuencias hist√≥ricas de los jugadores por jugada.\n\n- X_static ‚Üí informaci√≥n est√°tica de jugadores o de la jugada (por ejemplo posici√≥n inicial, rol, equipo).\n\n- Y ‚Üí targets a predecir (posiciones futuras de los jugadores).\n\n###  6.2 Divisi√≥n 80/20\n\nSe utiliza una proporci√≥n del 80% para entrenamiento y 20% para validaci√≥n, aplicando la misma semilla aleatoria para reproducibilidad. Esto asegura que:\n\n- El modelo vea suficientes ejemplos durante el entrenamiento.\n\n- La validaci√≥n refleje correctamente su capacidad de generalizaci√≥n a datos no vistos.\n\n###  6.3 Resultado\n\nDespu√©s de la divisi√≥n, se obtienen:\n\n- Conjunto de entrenamiento: X_seq_train, X_static_train, Y_train\n\n- Conjunto de validaci√≥n: X_seq_val, X_static_val, Y_val\n\nEsto permite entrenar modelos secuenciales como LSTM o Transformers usando secuencias hist√≥ricas, mientras se eval√∫a su desempe√±o en jugadas que no han sido vistas durante el entrenamiento.","metadata":{}},{"cell_type":"markdown","source":"## 7. Preparaci√≥n de Datasets TensorFlow y Dimensiones del Modelo","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# ------------------------------------------------------------\n# Definir tama√±o de lote (Batch Size)\n# ------------------------------------------------------------\nBATCH_SIZE = 128\nSHUFFLE_BUFFER = 2048 # Para mezclar los datos aleatoriamente\n\n# ------------------------------------------------------------\n# 1. Crear Dataset de Entrenamiento\n# ------------------------------------------------------------\ntrain_dataset = tf.data.Dataset.from_tensor_slices(\n    (\n        {\n            # IMPORTANTE: Estos nombres deben coincidir EXACTAMENTE con \n            # los names=\"\" definidos en layers.Input() del modelo.\n            \"seq_input\": X_seq_train,\n            \"static_input\": X_static_train\n        },\n        Y_train\n    )\n)\n\n# Pipeline optimizado:\n# 1. Shuffle: Mezclar datos (CR√çTICO para que aprenda bien)\n# 2. Batch: Agrupar\n# 3. Prefetch: Cargar el siguiente lote mientras la GPU procesa el actual\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n# ------------------------------------------------------------\n# 2. Crear Dataset de Validaci√≥n\n# ------------------------------------------------------------\nval_dataset = tf.data.Dataset.from_tensor_slices(\n    (\n        {\n            \"seq_input\": X_seq_val,\n            \"static_input\": X_static_val\n        },\n        Y_val\n    )\n)\n\n# En validaci√≥n NO hacemos shuffle (no es necesario y queremos orden estable)\nval_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\nprint(\"‚úÖ Pipelines de datos tf.data creados y optimizados.\")\nprint(f\"   - Batch Size: {BATCH_SIZE}\")\nprint(f\"   - Shuffle activo en entrenamiento\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:53:02.453821Z","iopub.execute_input":"2025-12-03T20:53:02.454535Z","iopub.status.idle":"2025-12-03T20:53:02.845249Z","shell.execute_reply.started":"2025-12-03T20:53:02.454514Z","shell.execute_reply":"2025-12-03T20:53:02.844511Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Pipelines de datos tf.data creados y optimizados.\n   - Batch Size: 128\n   - Shuffle activo en entrenamiento\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764795182.602501      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10658 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1764795182.603322      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ------------------------------------------------------------\n# Obtener las formas de los datos de entrenamiento\n# ------------------------------------------------------------\nseq_shape = X_seq_train.shape     # (N, T, P, F_seq)\nstatic_shape = X_static_train.shape  # (N, P, F_static)\ntarget_shape = Y_train.shape      # (N, P, H, 2) <--- OJO: P va antes que H\n\n# ------------------------------------------------------------\n# 1. Dimensi√≥n de Secuencia (T) - n√∫mero de frames hist√≥ricos\n# ------------------------------------------------------------\nT_SEQUENCE = seq_shape[1]\n\n# ------------------------------------------------------------\n# 2. N√∫mero de jugadores por jugada (P)\n# ------------------------------------------------------------\nP_PLAYERS = seq_shape[2]\n\n# ------------------------------------------------------------\n# 3. N√∫mero de features secuenciales por jugador (F_seq)\n# ------------------------------------------------------------\nF_SEQ_FEATURES = seq_shape[3]\n\n# ------------------------------------------------------------\n# 4. N√∫mero de features est√°ticas por jugador (F_static)\n# ------------------------------------------------------------\nF_STATIC_FEATURES = static_shape[2]\n\n# ------------------------------------------------------------\n# 5. Horizonte de predicci√≥n (H) - n√∫mero de frames futuros\n# ------------------------------------------------------------\n# CORRECCI√ìN: El horizonte est√° en el √≠ndice 2, no en el 1\nH_HORIZON = target_shape[2] \n\n# ------------------------------------------------------------\n# Imprimir dimensiones finales esenciales para la arquitectura del modelo\n# ------------------------------------------------------------\nprint(\"\\n--- üß© Dimensiones Finales del Modelo ---\")\nprint(f\"Secuencia (T): {T_SEQUENCE} frames (Historia de entrada)\")\nprint(f\"Jugadores (P): {P_PLAYERS} (Tama√±o fijo por jugada)\")\nprint(f\"Features Secuenciales (F_seq): {F_SEQ_FEATURES} features\")\nprint(f\"Features Est√°ticas (F_static): {F_STATIC_FEATURES} features\")\nprint(f\"Horizonte (H): {H_HORIZON} frames (Longitud de la predicci√≥n)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:53:02.845987Z","iopub.execute_input":"2025-12-03T20:53:02.846208Z","iopub.status.idle":"2025-12-03T20:53:02.852220Z","shell.execute_reply.started":"2025-12-03T20:53:02.846193Z","shell.execute_reply":"2025-12-03T20:53:02.851443Z"}},"outputs":[{"name":"stdout","text":"\n--- üß© Dimensiones Finales del Modelo ---\nSecuencia (T): 22 frames (Historia de entrada)\nJugadores (P): 10 (Tama√±o fijo por jugada)\nFeatures Secuenciales (F_seq): 7 features\nFeatures Est√°ticas (F_static): 3 features\nHorizonte (H): 10 frames (Longitud de la predicci√≥n)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Despu√©s de dividir los datos en entrenamiento y validaci√≥n, se crean los objetos tf.data.Dataset para un entrenamiento eficiente en GPU, y se extraen las dimensiones clave para definir la arquitectura del modelo.\n\n### 7.1 Creaci√≥n de datasets con tf.data.Dataset\n\nSe construyen dos datasets:\n\nDataset de entrenamiento: combina secuencias hist√≥ricas (X_seq_train), features est√°ticas (X_static_train) y targets (Y_train).\n\nDataset de validaci√≥n: an√°logo, usando los datos reservados para validaci√≥n.\n\nSe aplican las t√©cnicas de batching, cache y prefetch para optimizar la alimentaci√≥n de datos a la GPU durante el entrenamiento. Esto asegura que el modelo reciba los datos de manera r√°pida y eficiente, evitando cuellos de botella por lectura de memoria.\n\n### 7.2 Obtenci√≥n de las dimensiones del modelo\n\nPara definir correctamente la arquitectura del modelo (por ejemplo LSTM, Transformer o TabNet), se extraen las siguientes dimensiones del dataset:\n\n- Secuencia (T) ‚Üí n√∫mero de frames hist√≥ricos por jugada\n\n- N√∫mero de jugadores (P) ‚Üí tama√±o fijo de jugadores por jugada\n\n- Features secuenciales (F_seq) ‚Üí n√∫mero de caracter√≠sticas por jugador en cada frame\n\n- Features est√°ticas (F_static) ‚Üí n√∫mero de caracter√≠sticas est√°ticas por jugador\n\n- Horizonte de predicci√≥n (H) ‚Üí n√∫mero de frames futuros a predecir\n\n Estas dimensiones son esenciales para:\n\n- Construir las capas de entrada del modelo.\n\n- Definir el tama√±o de los tensores de entrada y salida.\n\n- Configurar correctamente las secuencias temporales y el procesamiento por jugador.\n\nAl finalizar, tanto los datasets de entrenamiento y validaci√≥n como las dimensiones del modelo est√°n listos para iniciar el entrenamiento de la red neuronal.","metadata":{}},{"cell_type":"markdown","source":"## 8. Arquitectura del Modelo","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# ------------------------------------------------------------\n# Definiciones principales\n# ------------------------------------------------------------\nMODEL_FILEPATH = 'best_football_model.keras'  # Ruta donde se guardar√° el mejor modelo\nPATIENCE = 10  # N√∫mero de √©pocas sin mejora antes de actuar\nEPOCHS = 100   # N√∫mero m√°ximo de √©pocas de entrenamiento\n\n# ------------------------------------------------------------\n# Definici√≥n de callbacks para el entrenamiento\n# ------------------------------------------------------------\ncallbacks_list = [\n    # 1. Guardar la mejor versi√≥n del modelo seg√∫n la p√©rdida de validaci√≥n\n    ModelCheckpoint(\n        filepath=MODEL_FILEPATH,\n        monitor='val_loss',\n        save_best_only=True,\n        verbose=1\n    ),\n    \n    # 2. Detener el entrenamiento si la p√©rdida de validaci√≥n no mejora\n    EarlyStopping(\n        monitor='val_loss',\n        patience=PATIENCE,\n        verbose=1,\n        restore_best_weights=True  # Restaura los pesos del mejor checkpoint\n    ),\n    \n    # 3. Reducir la tasa de aprendizaje si la p√©rdida de validaci√≥n se estanca\n    ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,              # Reduce LR a la mitad\n        patience=PATIENCE // 2,  # Espera la mitad de √©pocas que EarlyStopping\n        verbose=1\n    )\n]\n\nprint(\"‚úÖ Callbacks definidos para monitoreo y control.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:53:02.853048Z","iopub.execute_input":"2025-12-03T20:53:02.853368Z","iopub.status.idle":"2025-12-03T20:53:02.950429Z","shell.execute_reply.started":"2025-12-03T20:53:02.853347Z","shell.execute_reply":"2025-12-03T20:53:02.949707Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Callbacks definidos para monitoreo y control.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import numpy as np\n\n# ============================================================\n# BLOQUE DE CORRECCI√ìN DE DIMENSIONES (URGENTE)\n# ============================================================\nprint(\"üîß Corrigiendo formas de los datos para LSTM...\")\n\n# 1. Transponer X_seq: De (N, 22, 10, F) a (N, 10, 22, F)\n# El error ValueError anterior pas√≥ porque el modelo esperaba (Time, Players)\n# pero los datos estaban en (Players, Time). Esto lo arregla.\nif X_seq_train.shape[1] == 22 and X_seq_train.shape[2] == 10:\n    X_seq_train = X_seq_train.transpose(0, 2, 1, 3)\n    X_seq_val = X_seq_val.transpose(0, 2, 1, 3)\n    print(\"   -> Transposici√≥n aplicada: Ahora el tiempo (10) va primero.\")\nelse:\n    print(\"   -> Los datos ya ten√≠an la forma correcta, no se hizo cambios.\")\n\n# 2. Forzar las dimensiones correctas manualmente\n# Esto evita que el c√≥digo \"adivine\" mal las dimensiones T y P\nT_SEQUENCE = 10         # Frames de historia\nP_PLAYERS = 22          # Jugadores\nF_SEQ_FEATURES = X_seq_train.shape[3]    # Features din√°micas\nF_STATIC_FEATURES = X_static_train.shape[2] # Features est√°ticas\nH_HORIZON = 10          # Frames a predecir\n\nprint(f\"‚úÖ Datos Listos:\")\nprint(f\"   X_seq_train shape: {X_seq_train.shape} (Debe ser N, 10, 22, F)\")\nprint(f\"   X_static_train shape: {X_static_train.shape} (Debe ser N, 22, F)\")\n\nprint(\"\\n‚öôÔ∏è Variables de configuraci√≥n:\")\nprint(f\"   T_SEQUENCE (Tiempo): {T_SEQUENCE}\")\nprint(f\"   P_PLAYERS (Jugadores): {P_PLAYERS}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:53:02.951291Z","iopub.execute_input":"2025-12-03T20:53:02.951516Z","iopub.status.idle":"2025-12-03T20:53:02.957525Z","shell.execute_reply.started":"2025-12-03T20:53:02.951499Z","shell.execute_reply":"2025-12-03T20:53:02.956783Z"}},"outputs":[{"name":"stdout","text":"üîß Corrigiendo formas de los datos para LSTM...\n   -> Transposici√≥n aplicada: Ahora el tiempo (10) va primero.\n‚úÖ Datos Listos:\n   X_seq_train shape: (11286, 10, 22, 7) (Debe ser N, 10, 22, F)\n   X_static_train shape: (11286, 22, 3) (Debe ser N, 22, F)\n\n‚öôÔ∏è Variables de configuraci√≥n:\n   T_SEQUENCE (Tiempo): 10\n   P_PLAYERS (Jugadores): 22\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Dropout, Reshape, Concatenate, TimeDistributed, Flatten, Bidirectional\n\n# --- A. RE-CREAR DATASETS (Con los datos transpuestos) ---\nBATCH_SIZE = 128\nSHUFFLE_BUFFER = 2048\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    {\"seq_input\": X_seq_train, \"static_input\": X_static_train},\n    Y_train\n)).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\nval_dataset = tf.data.Dataset.from_tensor_slices((\n    {\"seq_input\": X_seq_val, \"static_input\": X_static_val},\n    Y_val\n)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n# --- B. RE-DEFINIR MODELO (Con P_PLAYERS=22 correcto) ---\nUNITS = 128\nDROPOUT_RATE = 0.2\nLSTM_OUTPUT_DIM = UNITS * 2\n\n# Inputs\ninput_seq = Input(shape=(T_SEQUENCE, P_PLAYERS, F_SEQ_FEATURES), name='seq_input')\ninput_static = Input(shape=(P_PLAYERS, F_STATIC_FEATURES), name='static_input')\n\n# Rama Secuencial (LSTM recorre los 10 frames)\nseq_flat = TimeDistributed(Flatten())(input_seq)\nx_seq = Bidirectional(LSTM(UNITS, return_sequences=False, dropout=DROPOUT_RATE))(seq_flat)\n\n# Rama Est√°tica\nstatic_flat = Flatten()(input_static)\nx_static = Dense(UNITS, activation='relu')(static_flat)\nx_static = Dropout(DROPOUT_RATE)(x_static)\n\n# Fusi√≥n\nx = Concatenate()([x_seq, x_static])\nx = Dense(LSTM_OUTPUT_DIM, activation='relu')(x)\nx = Dropout(DROPOUT_RATE)(x)\n\n# Salida\nOUTPUT_DIM = P_PLAYERS * H_HORIZON * 2\noutput_raw = Dense(OUTPUT_DIM, activation='linear')(x)\noutput = Reshape((P_PLAYERS, H_HORIZON, 2), name='output')(output_raw)\n\n# Compilar\nmodel = Model(inputs=[input_seq, input_static], outputs=output)\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='mse', metrics=['mae'])\n\nprint(\"‚úÖ Modelo y Datasets reconstruidos correctamente.\")\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:53:02.958345Z","iopub.execute_input":"2025-12-03T20:53:02.958594Z","iopub.status.idle":"2025-12-03T20:53:04.726396Z","shell.execute_reply.started":"2025-12-03T20:53:02.958578Z","shell.execute_reply":"2025-12-03T20:53:04.725807Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Modelo y Datasets reconstruidos correctamente.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ static_input        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m3\u001b[0m)     ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ seq_input           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m7\u001b[0m) ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)        ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ static_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m‚Ä¶\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ time_distributed    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m154\u001b[0m)   ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ seq_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n‚îÇ (\u001b[38;5;33mTimeDistributed\u001b[0m)   ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ      \u001b[38;5;34m8,576\u001b[0m ‚îÇ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ bidirectional       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       ‚îÇ    \u001b[38;5;34m289,792\u001b[0m ‚îÇ time_distributed‚Ä¶ ‚îÇ\n‚îÇ (\u001b[38;5;33mBidirectional\u001b[0m)     ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dropout (\u001b[38;5;33mDropout\u001b[0m)   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ concatenate         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ bidirectional[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n‚îÇ (\u001b[38;5;33mConcatenate\u001b[0m)       ‚îÇ                   ‚îÇ            ‚îÇ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dense_1 (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       ‚îÇ     \u001b[38;5;34m98,560\u001b[0m ‚îÇ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dense_2 (\u001b[38;5;33mDense\u001b[0m)     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m440\u001b[0m)       ‚îÇ    \u001b[38;5;34m113,080\u001b[0m ‚îÇ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ output (\u001b[38;5;33mReshape\u001b[0m)    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2\u001b[0m) ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ static_input        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)     ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ seq_input           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>) ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)        ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ static_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">‚Ä¶</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ time_distributed    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>)   ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ seq_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,576</span> ‚îÇ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ bidirectional       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">289,792</span> ‚îÇ time_distributed‚Ä¶ ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ concatenate         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       ‚îÇ                   ‚îÇ            ‚îÇ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       ‚îÇ     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> ‚îÇ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">440</span>)       ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">113,080</span> ‚îÇ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>) ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m510,008\u001b[0m (1.95 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">510,008</span> (1.95 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m510,008\u001b[0m (1.95 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">510,008</span> (1.95 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"Una vez que los datos est√°n listos y divididos en entrenamiento y validaci√≥n, se preparan los datasets de TensorFlow y se construye la arquitectura del modelo secuencial para predecir las trayectorias futuras de los jugadores.\n\n### 8.1 Datasets TensorFlow (tf.data.Dataset)\n\nSe crean dos datasets optimizados para GPU:\n\n- Dataset de entrenamiento: combina secuencias hist√≥ricas (X_seq_train), features est√°ticas (X_static_train) y targets (Y_train).\n\n- Dataset de validaci√≥n: usa los datos reservados para validaci√≥n.\n\n- Se aplican batching, cache y prefetch para mejorar la eficiencia en la alimentaci√≥n de datos a la GPU, evitando cuellos de botella durante el entrenamiento.\n\n### 8.2 Extracci√≥n de dimensiones del modelo\n\nAntes de definir la arquitectura, se extraen las dimensiones cr√≠ticas:\n\n- Secuencia (T) ‚Üí n√∫mero de frames hist√≥ricos.\n\n- N√∫mero de jugadores (P) ‚Üí tama√±o fijo por jugada.\n\n- Features secuenciales (F_seq) ‚Üí caracter√≠sticas por jugador y frame.\n\n- Features est√°ticas (F_static) ‚Üí caracter√≠sticas adicionales por jugador.\n\n- Horizonte de predicci√≥n (H) ‚Üí n√∫mero de frames futuros a predecir.\n\nEstas dimensiones son esenciales para configurar correctamente las capas de entrada y salida del modelo.\n\n### 8.3 Arquitectura del modelo Keras\n\nEl modelo combina dos flujos principales:\n\n- Flujo secuencial (LSTM bidireccional)\n\n- Procesa las secuencias hist√≥ricas de cada jugador.\n\n- Captura la informaci√≥n temporal y la din√°mica de los movimientos.\n\nFlujo est√°tico (Dense + Dropout)\n\n- Procesa las caracter√≠sticas est√°ticas de cada jugador.\n\n- Aporta informaci√≥n adicional que no depende del tiempo.\n\nEstos flujos se fusionan mediante una concatenaci√≥n y pasan por capas densas con activaci√≥n ReLU y Dropout para regularizaci√≥n. La capa de salida se ajusta con un reshape para producir la forma final:\n\n- (N_jugadas, P_PLAYERS, H_HORIZON, 2)\n\n- Cada jugador tiene H_HORIZON frames futuros con coordenadas (x, y).\n\n### 8.4 Compilaci√≥n del modelo\n\n- Optimizador: Adam con learning rate 1e-4\n\n- Funci√≥n de p√©rdida: MSE (error cuadr√°tico medio)\n\n- M√©trica: MAE (error absoluto medio)\n\nCon esto, el modelo est√° listo para entrenar sobre las secuencias hist√≥ricas y predecir trayectorias futuras de manera precisa y eficiente.","metadata":{}},{"cell_type":"markdown","source":"## 9. Entrenamiento del Modelo y Carga de Pesos √ìptimos","metadata":{}},{"cell_type":"code","source":"import pickle\n\nprint(\"\\n--- üèÉ Iniciando Entrenamiento (Intento Corregido) ---\")\n\nhistory = model.fit(\n    train_dataset,\n    epochs=EPOCHS,\n    validation_data=val_dataset,\n    callbacks=callbacks_list,\n    verbose=1\n)\n\nprint(\"\\n--- üéâ Entrenamiento Finalizado ---\")\n\n# Cargar mejores pesos\ntry:\n    model.load_weights(MODEL_FILEPATH)\n    print(\"‚úÖ Pesos cargados.\")\nexcept:\n    print(\"‚ö†Ô∏è No se cargaron pesos (quiz√°s no hubo mejora).\")\n\n# Guardar historial\nwith open('training_history.pkl', 'wb') as f:\n    pickle.dump(history.history, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:53:04.727061Z","iopub.execute_input":"2025-12-03T20:53:04.727295Z","iopub.status.idle":"2025-12-03T20:54:09.502564Z","shell.execute_reply.started":"2025-12-03T20:53:04.727278Z","shell.execute_reply":"2025-12-03T20:54:09.501974Z"}},"outputs":[{"name":"stdout","text":"\n--- üèÉ Iniciando Entrenamiento (Intento Corregido) ---\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1764795188.946701     122 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 90.4084 - mae: 4.8409\nEpoch 1: val_loss improved from inf to 0.54999, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - loss: 88.9475 - mae: 4.7714 - val_loss: 0.5500 - val_mae: 0.1735 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5436 - mae: 0.1880\nEpoch 2: val_loss improved from 0.54999 to 0.54997, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5435 - mae: 0.1880 - val_loss: 0.5500 - val_mae: 0.1729 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m85/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5342 - mae: 0.1768\nEpoch 3: val_loss improved from 0.54997 to 0.54996, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5341 - mae: 0.1766 - val_loss: 0.5500 - val_mae: 0.1724 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5267 - mae: 0.1706\nEpoch 4: val_loss improved from 0.54996 to 0.54995, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5268 - mae: 0.1706 - val_loss: 0.5500 - val_mae: 0.1720 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5164 - mae: 0.1661\nEpoch 5: val_loss improved from 0.54995 to 0.54994, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5165 - mae: 0.1661 - val_loss: 0.5499 - val_mae: 0.1716 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5264 - mae: 0.1678\nEpoch 6: val_loss improved from 0.54994 to 0.54994, saving model to best_football_model.keras\n\nEpoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5264 - mae: 0.1678 - val_loss: 0.5499 - val_mae: 0.1713 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5224 - mae: 0.1667\nEpoch 7: val_loss improved from 0.54994 to 0.54993, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5225 - mae: 0.1667 - val_loss: 0.5499 - val_mae: 0.1711 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5232 - mae: 0.1658\nEpoch 8: val_loss improved from 0.54993 to 0.54993, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5233 - mae: 0.1658 - val_loss: 0.5499 - val_mae: 0.1710 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5250 - mae: 0.1657\nEpoch 9: val_loss improved from 0.54993 to 0.54993, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5250 - mae: 0.1657 - val_loss: 0.5499 - val_mae: 0.1708 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5226 - mae: 0.1654\nEpoch 10: val_loss improved from 0.54993 to 0.54993, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5226 - mae: 0.1654 - val_loss: 0.5499 - val_mae: 0.1707 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m86/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5290 - mae: 0.1672\nEpoch 11: val_loss improved from 0.54993 to 0.54993, saving model to best_football_model.keras\n\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5288 - mae: 0.1672 - val_loss: 0.5499 - val_mae: 0.1705 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m82/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5209 - mae: 0.1639\nEpoch 12: val_loss improved from 0.54993 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5214 - mae: 0.1640 - val_loss: 0.5499 - val_mae: 0.1705 - learning_rate: 2.5000e-04\nEpoch 13/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5259 - mae: 0.1658\nEpoch 13: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5259 - mae: 0.1658 - val_loss: 0.5499 - val_mae: 0.1704 - learning_rate: 2.5000e-04\nEpoch 14/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5236 - mae: 0.1652\nEpoch 14: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5236 - mae: 0.1652 - val_loss: 0.5499 - val_mae: 0.1704 - learning_rate: 2.5000e-04\nEpoch 15/100\n\u001b[1m82/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5207 - mae: 0.1641\nEpoch 15: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5211 - mae: 0.1641 - val_loss: 0.5499 - val_mae: 0.1703 - learning_rate: 2.5000e-04\nEpoch 16/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5166 - mae: 0.1629\nEpoch 16: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\nEpoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5167 - mae: 0.1629 - val_loss: 0.5499 - val_mae: 0.1702 - learning_rate: 2.5000e-04\nEpoch 17/100\n\u001b[1m84/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5185 - mae: 0.1635\nEpoch 17: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5189 - mae: 0.1636 - val_loss: 0.5499 - val_mae: 0.1702 - learning_rate: 1.2500e-04\nEpoch 18/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5243 - mae: 0.1646\nEpoch 18: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5244 - mae: 0.1646 - val_loss: 0.5499 - val_mae: 0.1702 - learning_rate: 1.2500e-04\nEpoch 19/100\n\u001b[1m85/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5257 - mae: 0.1653\nEpoch 19: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5257 - mae: 0.1653 - val_loss: 0.5499 - val_mae: 0.1702 - learning_rate: 1.2500e-04\nEpoch 20/100\n\u001b[1m83/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5214 - mae: 0.1634\nEpoch 20: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5217 - mae: 0.1635 - val_loss: 0.5499 - val_mae: 0.1701 - learning_rate: 1.2500e-04\nEpoch 21/100\n\u001b[1m84/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5204 - mae: 0.1632\nEpoch 21: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\nEpoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5207 - mae: 0.1633 - val_loss: 0.5499 - val_mae: 0.1701 - learning_rate: 1.2500e-04\nEpoch 22/100\n\u001b[1m82/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5212 - mae: 0.1636\nEpoch 22: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5215 - mae: 0.1637 - val_loss: 0.5499 - val_mae: 0.1701 - learning_rate: 6.2500e-05\nEpoch 23/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5179 - mae: 0.1624\nEpoch 23: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5181 - mae: 0.1625 - val_loss: 0.5499 - val_mae: 0.1701 - learning_rate: 6.2500e-05\nEpoch 24/100\n\u001b[1m85/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5166 - mae: 0.1628\nEpoch 24: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5171 - mae: 0.1629 - val_loss: 0.5499 - val_mae: 0.1701 - learning_rate: 6.2500e-05\nEpoch 25/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5235 - mae: 0.1641\nEpoch 25: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5236 - mae: 0.1641 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 6.2500e-05\nEpoch 26/100\n\u001b[1m83/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5189 - mae: 0.1631\nEpoch 26: val_loss did not improve from 0.54992\n\nEpoch 26: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5194 - mae: 0.1632 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 6.2500e-05\nEpoch 27/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5260 - mae: 0.1646\nEpoch 27: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5260 - mae: 0.1646 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 3.1250e-05\nEpoch 28/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5256 - mae: 0.1645\nEpoch 28: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5256 - mae: 0.1645 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 3.1250e-05\nEpoch 29/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5250 - mae: 0.1644\nEpoch 29: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5250 - mae: 0.1644 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 3.1250e-05\nEpoch 30/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5195 - mae: 0.1636\nEpoch 30: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5197 - mae: 0.1636 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 3.1250e-05\nEpoch 31/100\n\u001b[1m86/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5202 - mae: 0.1625\nEpoch 31: val_loss did not improve from 0.54992\n\nEpoch 31: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5204 - mae: 0.1625 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 3.1250e-05\nEpoch 32/100\n\u001b[1m86/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5227 - mae: 0.1640\nEpoch 32: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5228 - mae: 0.1640 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 1.5625e-05\nEpoch 33/100\n\u001b[1m82/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5200 - mae: 0.1634\nEpoch 33: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5203 - mae: 0.1634 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 1.5625e-05\nEpoch 34/100\n\u001b[1m83/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5197 - mae: 0.1631\nEpoch 34: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5200 - mae: 0.1632 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 1.5625e-05\nEpoch 35/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5227 - mae: 0.1642\nEpoch 35: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5227 - mae: 0.1642 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 1.5625e-05\nEpoch 36/100\n\u001b[1m82/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5193 - mae: 0.1634\nEpoch 36: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\nEpoch 36: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5199 - mae: 0.1635 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 1.5625e-05\nEpoch 37/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5220 - mae: 0.1641\nEpoch 37: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5222 - mae: 0.1641 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 7.8125e-06\nEpoch 38/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5262 - mae: 0.1641\nEpoch 38: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5262 - mae: 0.1641 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 7.8125e-06\nEpoch 39/100\n\u001b[1m82/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5250 - mae: 0.1641\nEpoch 39: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5250 - mae: 0.1641 - val_loss: 0.5499 - val_mae: 0.1700 - learning_rate: 7.8125e-06\nEpoch 40/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5254 - mae: 0.1643\nEpoch 40: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5254 - mae: 0.1643 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 7.8125e-06\nEpoch 41/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5155 - mae: 0.1622\nEpoch 41: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\nEpoch 41: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5156 - mae: 0.1622 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 7.8125e-06\nEpoch 42/100\n\u001b[1m82/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5197 - mae: 0.1631\nEpoch 42: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5201 - mae: 0.1632 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 3.9063e-06\nEpoch 43/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5215 - mae: 0.1633\nEpoch 43: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5216 - mae: 0.1633 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 3.9063e-06\nEpoch 44/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5246 - mae: 0.1645\nEpoch 44: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5246 - mae: 0.1645 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 3.9063e-06\nEpoch 45/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5186 - mae: 0.1624\nEpoch 45: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5188 - mae: 0.1625 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 3.9063e-06\nEpoch 46/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5156 - mae: 0.1622\nEpoch 46: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\nEpoch 46: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5159 - mae: 0.1622 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 3.9063e-06\nEpoch 47/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5275 - mae: 0.1652\nEpoch 47: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5275 - mae: 0.1652 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.9531e-06\nEpoch 48/100\n\u001b[1m86/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5227 - mae: 0.1640\nEpoch 48: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5228 - mae: 0.1640 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.9531e-06\nEpoch 49/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5252 - mae: 0.1643\nEpoch 49: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5252 - mae: 0.1643 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.9531e-06\nEpoch 50/100\n\u001b[1m84/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5251 - mae: 0.1643\nEpoch 50: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5251 - mae: 0.1643 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.9531e-06\nEpoch 51/100\n\u001b[1m84/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5231 - mae: 0.1638\nEpoch 51: val_loss did not improve from 0.54992\n\nEpoch 51: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5231 - mae: 0.1638 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.9531e-06\nEpoch 52/100\n\u001b[1m82/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5126 - mae: 0.1610\nEpoch 52: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5137 - mae: 0.1612 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 9.7656e-07\nEpoch 53/100\n\u001b[1m84/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5260 - mae: 0.1647\nEpoch 53: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5260 - mae: 0.1647 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 9.7656e-07\nEpoch 54/100\n\u001b[1m86/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5175 - mae: 0.1622\nEpoch 54: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5179 - mae: 0.1623 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 9.7656e-07\nEpoch 55/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5244 - mae: 0.1643\nEpoch 55: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5244 - mae: 0.1643 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 9.7656e-07\nEpoch 56/100\n\u001b[1m85/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5227 - mae: 0.1635\nEpoch 56: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\nEpoch 56: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5228 - mae: 0.1635 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 9.7656e-07\nEpoch 57/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5266 - mae: 0.1651\nEpoch 57: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5266 - mae: 0.1651 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 4.8828e-07\nEpoch 58/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5217 - mae: 0.1637\nEpoch 58: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5217 - mae: 0.1637 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 4.8828e-07\nEpoch 59/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5257 - mae: 0.1642\nEpoch 59: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5257 - mae: 0.1642 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 4.8828e-07\nEpoch 60/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5189 - mae: 0.1628\nEpoch 60: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5191 - mae: 0.1628 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 4.8828e-07\nEpoch 61/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5228 - mae: 0.1632\nEpoch 61: val_loss did not improve from 0.54992\n\nEpoch 61: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5229 - mae: 0.1633 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 4.8828e-07\nEpoch 62/100\n\u001b[1m84/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5229 - mae: 0.1640\nEpoch 62: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5231 - mae: 0.1640 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 2.4414e-07\nEpoch 63/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5222 - mae: 0.1635\nEpoch 63: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5222 - mae: 0.1635 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 2.4414e-07\nEpoch 64/100\n\u001b[1m85/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5166 - mae: 0.1622\nEpoch 64: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5171 - mae: 0.1623 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 2.4414e-07\nEpoch 65/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5162 - mae: 0.1619\nEpoch 65: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5165 - mae: 0.1620 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 2.4414e-07\nEpoch 66/100\n\u001b[1m85/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5216 - mae: 0.1632\nEpoch 66: val_loss improved from 0.54992 to 0.54992, saving model to best_football_model.keras\n\nEpoch 66: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.5219 - mae: 0.1632 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 2.4414e-07\nEpoch 67/100\n\u001b[1m83/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5233 - mae: 0.1642\nEpoch 67: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5235 - mae: 0.1641 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.2207e-07\nEpoch 68/100\n\u001b[1m88/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5222 - mae: 0.1641\nEpoch 68: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5222 - mae: 0.1641 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.2207e-07\nEpoch 69/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5133 - mae: 0.1609\nEpoch 69: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5137 - mae: 0.1610 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.2207e-07\nEpoch 70/100\n\u001b[1m82/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5278 - mae: 0.1647\nEpoch 70: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5275 - mae: 0.1646 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.2207e-07\nEpoch 71/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5183 - mae: 0.1627\nEpoch 71: val_loss did not improve from 0.54992\n\nEpoch 71: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5185 - mae: 0.1628 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 1.2207e-07\nEpoch 72/100\n\u001b[1m87/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5232 - mae: 0.1637\nEpoch 72: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5233 - mae: 0.1637 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 6.1035e-08\nEpoch 73/100\n\u001b[1m84/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5240 - mae: 0.1642\nEpoch 73: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5241 - mae: 0.1642 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 6.1035e-08\nEpoch 74/100\n\u001b[1m84/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5184 - mae: 0.1629\nEpoch 74: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5188 - mae: 0.1630 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 6.1035e-08\nEpoch 75/100\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5259 - mae: 0.1648\nEpoch 75: val_loss did not improve from 0.54992\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5259 - mae: 0.1648 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 6.1035e-08\nEpoch 76/100\n\u001b[1m86/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.5135 - mae: 0.1613\nEpoch 76: val_loss did not improve from 0.54992\n\nEpoch 76: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n\u001b[1m89/89\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.5140 - mae: 0.1614 - val_loss: 0.5499 - val_mae: 0.1699 - learning_rate: 6.1035e-08\nEpoch 76: early stopping\nRestoring model weights from the end of the best epoch: 66.\n\n--- üéâ Entrenamiento Finalizado ---\n‚úÖ Pesos cargados.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"Una vez preparados los datasets y la arquitectura del modelo, se procede al entrenamiento supervisado con las secuencias hist√≥ricas y targets de predicci√≥n.\n\n### 9.1 Proceso de entrenamiento\n\n- Se utiliza el dataset de entrenamiento (train_dataset) para ajustar los pesos de la red.\n\n- El dataset de validaci√≥n (val_dataset) permite monitorear la capacidad de generalizaci√≥n del modelo durante el entrenamiento.\n\n- Se aplican callbacks definidos previamente:\n\n    - ModelCheckpoint: guarda la mejor versi√≥n del modelo seg√∫n la p√©rdida de validaci√≥n.\n\n    - EarlyStopping: detiene el entrenamiento si no hay mejora tras un n√∫mero determinado de √©pocas.\n\n    - ReduceLROnPlateau: reduce la tasa de aprendizaje si la p√©rdida de validaci√≥n se estanca.\n\n### 9.2 Resultados del entrenamiento\n\n- El entrenamiento se ejecuta durante un n√∫mero m√°ximo de √©pocas, pero puede detenerse antes gracias a EarlyStopping.\n\n- El progreso se muestra en consola, incluyendo p√©rdida y m√©tricas tanto en entrenamiento como en validaci√≥n.\n\n### 9.3 Carga de los mejores pesos\n\n- Despu√©s de finalizar el entrenamiento, se cargan los pesos del mejor modelo guardado por ModelCheckpoint.\n\n- Esto garantiza que el modelo final tenga el mejor desempe√±o en validaci√≥n, listo para evaluaci√≥n o inferencia.","metadata":{}},{"cell_type":"markdown","source":"## 10. Evaluaci√≥n del Modelo: ADE y FDE","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# ------------------------------------------------------------\n# Validaci√≥n con Reconstrucci√≥n de Trayectoria (Nivel Pro)\n# ------------------------------------------------------------\n\nprint(\"1. Generando predicciones (Deltas)...\")\n# El modelo devuelve \"cu√°nto se movi√≥\", no \"d√≥nde est√°\"\npred_deltas = model.predict(val_dataset) # Shape: (N, P, H, 2)\n\n# ------------------------------------------------------------\n# 2. Reconstrucci√≥n de Coordenadas Absolutas\n# ------------------------------------------------------------\n# Para saber el error real en metros, debemos sumar los deltas a la posici√≥n inicial.\n\n# Obtenemos la √∫ltima posici√≥n conocida (Frame T=10 de la entrada)\n# Asumimos que las columnas 0 y 1 de X_seq son 'x' y 'y'\ninitial_pos = X_seq_val[:, -1, :, 0:2] # Shape: (N, P, 2)\n\n# Expandimos para poder sumar con broadcasting: (N, P, 1, 2)\ninitial_pos_expanded = np.expand_dims(initial_pos, axis=2)\n\n# Aplicamos suma acumulativa (cumsum) a los deltas\n# Si predijo [+1, +1, +1], la trayectoria es [1, 2, 3]\npred_abs = initial_pos_expanded + np.cumsum(pred_deltas, axis=2)\ny_val_abs = initial_pos_expanded + np.cumsum(Y_val, axis=2)\n\n# ------------------------------------------------------------\n# 3. C√°lculo de M√©tricas (ADE / FDE)\n# ------------------------------------------------------------\ndef calculate_displacement_metrics(y_true, y_pred):\n    # Diferencia entre coordenadas reconstruidas\n    diff = y_pred - y_true \n    # Distancia Euclidiana (Pit√°goras)\n    dist = np.sqrt(np.sum(diff**2, axis=-1)) # (N, P, H)\n    \n    # ADE: Promedio de error en todos los frames del horizonte\n    ade = np.mean(dist)\n    \n    # FDE: Promedio de error SOLO en el √∫ltimo frame (H=10)\n    fde = np.mean(dist[:, :, -1])\n    \n    return ade, fde\n\nade, fde = calculate_displacement_metrics(y_val_abs, pred_abs)\n\nprint(\"\\n\" + \"=\"*40)\nprint(\"üìä RESULTADOS FINALES DE VALIDACI√ìN\")\nprint(\"=\"*40)\nprint(f\"‚úÖ ADE (Error Promedio): {ade:.4f} metros\")\nprint(f\"‚úÖ FDE (Error Final):    {fde:.4f} metros\")\n\n# Interpretaci√≥n\nif ade < 2.0:\n    print(\"üåü ¬°EXCELENTE! El modelo es muy preciso.\")\nelif ade < 3.5:\n    print(\"üëç BUENO. Es un resultado competitivo.\")\nelse:\n    print(\"‚ö†Ô∏è MEJORABLE. Revisa si la normalizaci√≥n de datos es correcta.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:54:09.503303Z","iopub.execute_input":"2025-12-03T20:54:09.503550Z","iopub.status.idle":"2025-12-03T20:54:10.255316Z","shell.execute_reply.started":"2025-12-03T20:54:09.503533Z","shell.execute_reply":"2025-12-03T20:54:10.254623Z"}},"outputs":[{"name":"stdout","text":"1. Generando predicciones (Deltas)...\n\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n\n========================================\nüìä RESULTADOS FINALES DE VALIDACI√ìN\n========================================\n‚úÖ ADE (Error Promedio): 1.0608 metros\n‚úÖ FDE (Error Final):    2.6567 metros\nüåü ¬°EXCELENTE! El modelo es muy preciso.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"Despu√©s de entrenar el modelo, es importante medir su desempe√±o sobre datos no vistos (conjunto de validaci√≥n). Para ello, se calculan m√©tricas de error espec√≠ficas para predicci√≥n de trayectorias.\n\n### 10.1 Predicciones del modelo\n\n- Se obtiene la salida del modelo usando model.predict sobre el dataset de validaci√≥n (val_dataset).\n\n- La forma de las predicciones es (N_val, P_PLAYERS, H_HORIZON, 2), correspondiendo a las coordenadas (x, y) de cada jugador en cada frame futuro.\n\n### 10.2 M√©tricas de desempe√±o\n\nSe utilizan principalmente dos m√©tricas de desplazamiento:\n\n- ADE (Average Displacement Error)\n\n    - Calcula el error promedio entre la posici√≥n predicha y la real para cada frame del horizonte de predicci√≥n.\n\n    - Indica qu√© tan precisas son las trayectorias a lo largo del tiempo.\n\n- FDE (Final Displacement Error)\n\n    - Calcula el error √∫nicamente en el √∫ltimo frame del horizonte.\n\n    - Eval√∫a la precisi√≥n en la posici√≥n final predicha.\n\n### 10.3 Interpretaci√≥n\n\n- Valores m√°s bajos de ADE y FDE indican mejores predicciones.\n\n- Estas m√©tricas son est√°ndar en tareas de predicci√≥n de trayectorias de jugadores en deportes o veh√≠culos aut√≥nomos.\n\n- Permiten comparar diferentes modelos o configuraciones de entrenamiento de forma cuantitativa.","metadata":{}},{"cell_type":"markdown","source":"## 11. Submission","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport cudf\nimport cupy as cp\nimport numpy as np\nfrom tqdm.auto import tqdm\n\n# =========================================================\n# BLOQUE DE RECUPERACI√ìN DE FUNCIONES (CORREGIDO)\n# =========================================================\n\n# 1. Funci√≥n para cargar datos\ndef load_test_data():\n    print(\"üìÇ Cargando archivos CSV de Test...\")\n    try:\n        test_input = cudf.read_csv('/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv')\n    except:\n        print(\"‚ö†Ô∏è Usando pandas fallback para carga\")\n        test_input = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv')\n        test_input = cudf.from_pandas(test_input)\n        \n    try:\n        test_targets = cudf.read_csv('/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv')\n    except:\n        test_targets = None\n        \n    return test_input, test_targets\n\n# 2. Funci√≥n de Ingenier√≠a de Features\ndef engineer_frame_features_gpu(input_df, output_df):\n    df = input_df.copy()\n    df = df.sort_values([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])\n    \n    # Altura\n    if \"player_height\" in df.columns:\n        split = df[\"player_height\"].astype(\"str\").str.split(\"-\", expand=True)\n        feet = split.iloc[:, 0].astype(\"float32\")\n        inches = split.iloc[:, 1].astype(\"float32\")\n        df[\"height_inches\"] = feet * 12 + inches\n        df = df.drop(columns=[\"player_height\"])\n    \n    # Casting\n    df[\"speed\"] = df[\"s\"].astype(\"float32\")\n    df[\"acceleration\"] = df[\"a\"].astype(\"float32\")\n    \n    # Dir Radianes\n    if \"dir\" in df.columns:\n        df[\"dir_rad\"] = df[\"dir\"].astype(\"float32\") * (np.pi / 180.0)\n    else:\n        df[\"dir_rad\"] = 0.0\n        \n    # Velocidades XY\n    cp_dir_rad = df[\"dir_rad\"].to_cupy()\n    cp_speed = df[\"speed\"].to_cupy()\n    df[\"vx\"] = cudf.Series(cp_speed * cp.cos(cp_dir_rad))\n    df[\"vy\"] = cudf.Series(cp_speed * cp.sin(cp_dir_rad))\n    \n    # Encoding\n    for col in [\"player_position\", \"player_role\"]:\n        if col in df.columns:\n            df[col] = df[col].astype(\"category\")\n            df[f\"{col}_encoded\"] = df[col].cat.codes.astype(\"int16\")\n            \n    return {\"df_final\": df, \"output_df\": output_df}\n\n# 3. Reducci√≥n de Memoria\ndef reduce_memory_footprint_gpu(df):\n    for col in df.columns:\n        if df[col].dtype == 'float64':\n            df[col] = df[col].astype('float32')\n    return df\n\n# 4. Construcci√≥n de Dataset TEST (CON FIX FINAL)\ndef build_play_level_dataset_test(input_df, seq_len=10, max_players=22):\n    possible_cols = [\"x\",\"y\",\"speed\",\"acceleration\",\"vx\",\"vy\",\"dir_rad\"]\n    feat_cols = [c for c in possible_cols if c in input_df.columns]\n    num_feats = len(feat_cols)\n    static_cols = [c for c in [\"height_inches\", \"player_weight\", \"player_position_encoded\"] if c in input_df.columns]\n    num_static_feats = len(static_cols)\n    \n    unique_plays = input_df[[\"game_id\", \"play_id\"]].drop_duplicates().to_pandas()\n    \n    X_seq_list = []\n    X_static_list = []\n    X_initials_list = []\n    meta_list = []\n    \n    for row in tqdm(unique_plays.itertuples(index=False), total=len(unique_plays), desc=\"Test Dataset\"):\n        gid, pid = row.game_id, row.play_id\n        df_play = input_df[(input_df.game_id == gid) & (input_df.play_id == pid)].sort_values([\"nfl_id\", \"frame_id\"])\n        players = df_play[\"nfl_id\"].unique().to_cupy()\n        \n        X_seq_play = cp.zeros((max_players, seq_len, num_feats), dtype=cp.float32)\n        X_static_play = cp.zeros((max_players, num_static_feats), dtype=cp.float32)\n        initial_pos_play = np.zeros((max_players, 2), dtype=np.float32)\n        \n        players_meta = []\n        \n        for i, nfl_id_gpu in enumerate(players[:max_players]):\n            nfl_id = nfl_id_gpu.item()\n            players_meta.append(nfl_id)\n            \n            p_data = df_play[df_play.nfl_id == nfl_id]\n            seq_vals = p_data[feat_cols].tail(seq_len).to_cupy()\n            \n            if len(seq_vals) > 0:\n                X_seq_play[i, -len(seq_vals):, :] = seq_vals\n                if len(p_data) > 0:\n                    X_static_play[i, :] = p_data[static_cols].iloc[0].to_cupy()\n                \n                # --- FIX: Convertir a .item() (CPU) ---\n                curr_x = seq_vals[-1, 0].item()\n                curr_y = seq_vals[-1, 1].item()\n                initial_pos_play[i, :] = [curr_x, curr_y]\n                # --------------------------------------\n                \n        X_seq_list.append(cp.asnumpy(X_seq_play))\n        X_static_list.append(cp.asnumpy(X_static_play))\n        X_initials_list.append(initial_pos_play)\n        meta_list.append({\"game_id\": gid, \"play_id\": pid, \"players\": players_meta})\n        \n    return {\n        \"X_seq\": np.array(X_seq_list),\n        \"X_static\": np.array(X_static_list),\n        \"X_initials\": np.array(X_initials_list),\n        \"meta_list\": meta_list\n    }\n\nprint(\"‚úÖ Funciones de Test REPARADAS.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:54:10.256213Z","iopub.execute_input":"2025-12-03T20:54:10.256500Z","iopub.status.idle":"2025-12-03T20:54:10.272803Z","shell.execute_reply.started":"2025-12-03T20:54:10.256476Z","shell.execute_reply":"2025-12-03T20:54:10.272098Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Funciones de Test REPARADAS.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# =========================================================================\n# BLOQUE FINAL: GENERACI√ìN DE ARCHIVO DE SUMISI√ìN\n# =========================================================================\n\nprint(\"\\nüöÄ INICIANDO PROCESO DE SUMISI√ìN...\")\n\n# 1. Cargar\nprint(\"1. Cargando datos...\")\ntest_input, test_targets = load_test_data()\n\n# 2. Features\nprint(\"2. Ingenier√≠a de Features...\")\nfe_test = engineer_frame_features_gpu(test_input, test_input)\ndf_final_test = fe_test[\"df_final\"]\ndf_final_test = reduce_memory_footprint_gpu(df_final_test)\n\n# 3. Dataset\nprint(\"3. Construyendo tensores...\")\ntest_dataset = build_play_level_dataset_test(\n    input_df=df_final_test,\n    seq_len=CONFIG[\"sequence_length\"],\n    max_players=CONFIG[\"max_players\"]\n)\n\nX_seq_test = test_dataset[\"X_seq\"]\nX_static_test = test_dataset[\"X_static\"]\nX_initials_test = test_dataset[\"X_initials\"]\nmeta_test = test_dataset[\"meta_list\"]\n\n# Transponer para que coincida con el modelo (N, 10, 22, F)\nprint(f\"   Forma original: {X_seq_test.shape}\")\nX_seq_test = X_seq_test.transpose(0, 2, 1, 3)\nprint(f\"   Forma corregida: {X_seq_test.shape}\")\n\n# 4. Predicci√≥n\nprint(\"4. Prediciendo...\")\ndeltas_pred = model.predict(\n    {\"seq_input\": X_seq_test, \"static_input\": X_static_test},\n    batch_size=CONFIG[\"batch_size\"],\n    verbose=1\n)\n\n# 5. Reconstrucci√≥n\nprint(\"5. Reconstruyendo absolutos...\")\ninitials_expanded = X_initials_test[:, :, np.newaxis, :]\nabs_preds = initials_expanded + np.cumsum(deltas_pred, axis=2)\n\n# 6. CSV\nprint(\"6. Guardando CSV...\")\nsubmission_rows = []\n\nfor i, meta in enumerate(meta_test):\n    gid, pid = meta[\"game_id\"], meta[\"play_id\"]\n    players = meta[\"players\"]\n    \n    for p_idx, nfl_id in enumerate(players):\n        for frame in range(CONFIG[\"max_frames_to_predict\"]):\n            submission_rows.append({\n                \"game_play_id\": f\"{gid}_{pid}\",\n                \"nfl_id\": int(nfl_id),\n                \"step\": frame + 1,\n                \"x\": float(abs_preds[i, p_idx, frame, 0]),\n                \"y\": float(abs_preds[i, p_idx, frame, 1])\n            })\n\nsub_df = pd.DataFrame(submission_rows)\nsub_df = sub_df[[\"game_play_id\", \"nfl_id\", \"step\", \"x\", \"y\"]]\nsub_df.to_csv(\"submission.csv\", index=False)\n\nprint(\"\\n\" + \"=\"*50)\nprint(f\"‚úÖ ¬°ARCHIVO GENERADO! Filas: {len(sub_df)}\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:54:10.273650Z","iopub.execute_input":"2025-12-03T20:54:10.273968Z","iopub.status.idle":"2025-12-03T20:54:30.743357Z","shell.execute_reply.started":"2025-12-03T20:54:10.273929Z","shell.execute_reply":"2025-12-03T20:54:30.742573Z"}},"outputs":[{"name":"stdout","text":"\nüöÄ INICIANDO PROCESO DE SUMISI√ìN...\n1. Cargando datos...\nüìÇ Cargando archivos CSV de Test...\n2. Ingenier√≠a de Features...\n3. Construyendo tensores...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Test Dataset:   0%|          | 0/143 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d21baf475ec43b0b446bd765c81133f"}},"metadata":{}},{"name":"stdout","text":"   Forma original: (143, 22, 10, 7)\n   Forma corregida: (143, 10, 22, 7)\n4. Prediciendo...\n\u001b[1m5/5\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n5. Reconstruyendo absolutos...\n6. Guardando CSV...\n\n==================================================\n‚úÖ ¬°ARCHIVO GENERADO! Filas: 17580\n==================================================\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\n\nprint(\"üîç Verificando archivo de sumisi√≥n...\")\n\n# 1. Verificar si existe en el directorio actual\nif os.path.exists(\"submission.csv\"):\n    print(\"‚úÖ ¬°Encontrado! El archivo 'submission.csv' existe en el directorio actual.\")\n    \n    # 2. Verificar contenido r√°pido\n    df_check = pd.read_csv(\"submission.csv\")\n    print(f\"   - Filas encontradas: {len(df_check)}\")\n    print(f\"   - Columnas: {list(df_check.columns)}\")\n    \n    # 3. Mover a /kaggle/working por seguridad (si no est√° ah√≠)\n    # En Kaggle, el directorio de salida por defecto es /kaggle/working\n    current_dir = os.getcwd()\n    target_dir = \"/kaggle/working\"\n    \n    if current_dir != target_dir:\n        print(f\"‚ö†Ô∏è El archivo est√° en {current_dir}, movi√©ndolo a {target_dir}...\")\n        try:\n            shutil.copy(\"submission.csv\", \"/kaggle/working/submission.csv\")\n            print(\"‚úÖ Archivo copiado exitosamente a la carpeta de salida.\")\n        except Exception as e:\n            print(f\"‚ùå Error al mover: {e}\")\n    else:\n        print(\"‚úÖ El archivo ya est√° en la carpeta correcta (/kaggle/working).\")\n\nelse:\n    print(\"‚ùå ERROR CR√çTICO: No se encuentra 'submission.csv'.\")\n    print(\"   -> ¬øEjecutaste el bloque anterior ('BLOQUE FINAL')?\")\n    print(\"   -> Revisa si hubo alg√∫n error rojo en ese bloque.\")\n\nprint(\"\\nüìÇ Listando archivos en el directorio de salida:\")\nprint(os.listdir(\"/kaggle/working\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:54:30.746233Z","iopub.execute_input":"2025-12-03T20:54:30.746501Z","iopub.status.idle":"2025-12-03T20:54:30.767603Z","shell.execute_reply.started":"2025-12-03T20:54:30.746482Z","shell.execute_reply":"2025-12-03T20:54:30.766875Z"}},"outputs":[{"name":"stdout","text":"üîç Verificando archivo de sumisi√≥n...\n‚úÖ ¬°Encontrado! El archivo 'submission.csv' existe en el directorio actual.\n   - Filas encontradas: 17580\n   - Columnas: ['game_play_id', 'nfl_id', 'step', 'x', 'y']\n‚úÖ El archivo ya est√° en la carpeta correcta (/kaggle/working).\n\nüìÇ Listando archivos en el directorio de salida:\n['best_football_model.keras', 'submission.csv', '.virtual_documents', 'training_history.pkl', 'data_play_level.npz', 'meta_list.pkl']\n","output_type":"stream"}],"execution_count":22}]}